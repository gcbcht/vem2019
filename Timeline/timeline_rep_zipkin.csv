REPOSITORY,ISSUE_ID,STATUS,EVENT,CREATED_AT,TIME DURATION,NEGATIVE,NEUTRAL,POSITIVE,MSG,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,opened,2012-10-29 23:05:27,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,title,2012-10-29 23:05:27,00:00,,1,,"b""b' Publish to Maven Central'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,body,2012-10-29 23:05:27,00:00,,,1,"b""b' I discussed with @franklinhu on creating a Sonatype OSS account:url  This would allow us to publish artifacts directly to Maven Central and be good open source citizens.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,1,2012-10-29 23:05:27,44.47,,1,,"b""b' Why is it better to be on Sonatype OSS than ?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,2,2012-10-29 23:05:27,6.0,,1,,"b'b"" Because it automatically syncs to Maven Central. I\'m slowly weaning Twitter off of  for most things and having artifacts published to Maven Central instead.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,3,2012-10-29 23:05:27,9.33,,,1,"b""b' Neat"," good to know.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,4,2012-10-29 23:05:27,16.65,,1,,"b""b' Filed the ticket: url @caniszczyk can you sanity check that?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,5,2012-10-29 23:05:27,2.83,,,1,"b""b' Looks fine", would be great to have this change coincide moving to Maven :) To sync to maven central," we need spruce up our POM most likely with extra metadata:url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,6,2012-10-29 23:05:27,388.73,,1,,"b""b' So"," has anything been published yet?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,7,2012-10-29 23:05:27,1027.95,,1,,"b""b' @caniszczyk seems like the last release was end of Aug"," 2013 -any chance of cutting a new release and publishing it to sonatype?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,8,2012-10-29 23:05:27,36.72,,1,,"b'b"" @jpinner Yes. We\'re working on scheduling it now.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,9,2012-10-29 23:05:27,945.65,,1,,"b""b' any updates?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,10,2012-10-29 23:05:27,4.92,,,1,"b""b' I think the idea is that openzipkin will drive artifact publication @rtyler can invite you to the org as well!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,11,2012-10-29 23:05:27,800.27,,1,,"b""b' The url  org includes a zipkin-core team which has jpinner in it now too. The plan is to publish artifacts to url  after merging some in-flight sbt-bintray  work Lookout built.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,12,2012-10-29 23:05:27,630.48,,,1,"b'b"" Just to touch this again. Inside Twitter", maven central is the preferred repo, and our pants 3rdparty will only look at that and url  I can manually push to the latter until central sync is supported. That would be ideally something that\'s already published to bintray. Once something is published somewhere, I can move twitter onto openzipkin," which would be very sweet.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,13,2012-10-29 23:05:27,175.3,,1,,"b""b' @rtyler @eirslett @michaelsembwever @kristofa @jamescway (think this is openzipkin founding parents)... So", are you thinking :zipkin-whatev? Once we decide on group id," I can start the sonatype ticket.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,closed,2015-07-17 19:14:45,1209.3,0,10,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,reopened,2015-07-17 19:14:48,0.05,0,10,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,14,2012-10-29 23:05:27,204.7,1,,,"b""b' Twitter donated  to us. @aasta has access to the godaddy stuff. I suspect we could use this for group id"," etc? cc @eirslett @rtyler '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,15,2012-10-29 23:05:27,3.78,,,1,"b""b' Fantastic"," thanks a lot! :-) it is!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,16,2012-10-29 23:05:27,13.1,,,1,"b'b"" @adriancole sounds good to me"," can you get twitter to just point  at GitHub\'s nameservers for CNAME purposes?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,17,2012-10-29 23:05:27,11.02,,1,,"b'b"" @rtyler I just added you to have manage products ability on godaddy"," solemme know if that didn\'t work.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,18,2012-10-29 23:05:27,1033.98,,1,,"b'b"" url  I\'d like a backup.. @eirslett @michaelsembwever @abesto @kristofa @aasta .. can one or more of you register on url  and add a comment ^^ with your username?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,19,2012-10-29 23:05:27,415.85,,,1,"b'b"" soo.. we did this"," and it didn\'t even take 3 years! url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,closed,2015-08-21 23:17:11,242.38,1,12,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,194,closed,-,-,-,1,12,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,opened,2013-05-01 22:38:20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,title,2013-05-01 22:38:20,00:00,,1,,"b""b' Update build system to SBT 0.12.3 and update all dependencies to latest version'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,body,2013-05-01 22:38:20,00:00,,1,,"b""b' SBT to 0.12.3All build plugins ported and inlinedzipkin-hadoop removedall dependencies on latest versionsall deprecation warnings for dependencies removed'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,1,2013-05-01 22:38:20,1.07,,1,,"b""b' This build is going to fail because it depends on an unreleased version of finagle.  They should release finagle real soon now in which case this will start working.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,2,2013-05-01 22:38:20,1317.05,,1,,"b'b"" This is quite the beast of a branch. Generally it would be easier to review if it was split into a few different pull requests. Seems there\'s a couple of things happening: removing hadoop component", upgrading sbt, upgrading dependencies and cleaning up the deprecation notices. Do they all have to be done in one go?I can\'t remember," what was the reason for removing the Hadoop module?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,3,2013-05-01 22:38:20,10.42,,1,,"b'b"" A lot of these things cascade into the others.  Hadoop didn\'t work as itwas", and it won\'t even compile on the new libs.  Scrooge won\'t compile onsbt11, finagle5 won\'t play well with sbt12 scrooge.  So now we\'ve upgradedall the libs, upgraded sbt, deleted hadoop. The deprecation warnings were the previous commit, just because I wanted tomerge this big change into a clean build.  If you want to see the diffwithout them just go one rev back. On Fri, May 17, 2013 at 1:36 PM," Johan Oskarssonnotifications@:""'",,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,4,2013-05-01 22:38:20,2.73,,1,,"b'b"" BTW", regarding the hadoop stuff," I\'m working on an updated hadoop environment based on the latest scalding.  That will be submitted back in a separate commit.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,5,2013-05-01 22:38:20,76.47,,1,,"b""b' Is this change something that is required by sbt? Otherwise it would be preferable to keep the same directory structure as all other projects:zipkin\\xe2\\x86\\x92 ../'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,6,2013-05-01 22:38:20,1.08,,1,,"b'b"" Beyond the above comments it gets a +1 for me", but we should make sure at least Franklin reviews it too since it\'s i a massive change. I kind of skimmed most of the sbt stuff," don\'t think I can provide much in terms of useful feedback there.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,7,2013-05-01 22:38:20,23.38,,1,,"b""b' @johanoskarsson the thrift moving to resources is in order to build a properly formatted thrift idl jar.  Pants gets grumpy unless you put the files in a certain directory and name the jar a certain way.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,closed,2013-05-18 01:40:44,182.4,0,9,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,reopened,2013-05-18 01:41:12,0.47,0,9,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,8,2013-05-01 22:38:20,191.08,,1,,"b""b' Repushed with deprecation warnings reset.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,9,2013-05-01 22:38:20,936.85,,1,,"b""b' +1 fire at will'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,closed,2013-05-20 17:21:12,940.0,0,11,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,242,closed,-,-,-,0,11,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,260,closed,opened,2013-06-14 00:58:46,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,260,closed,title,2013-06-14 00:58:46,00:00,,1,,"b""b' Make traces and spans monoids'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,260,closed,body,2013-06-14 00:58:46,00:00,,1,,"b""b' Adding two spans with the same id will merge their annotations.Adding two traces with the same id will merge their spans.This is the basis for  jobs to coalesce spans into traces.TODO use the monoid for this behavior in the rest of the code.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,260,closed,1,2013-06-14 00:58:46,643.43,,1,,"b""b' So the set of spans with the same id is one monoid", (identity is the span without annotations)," the set of traces with the same id is another monoid (identity is the trace without any spans)?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,260,closed,2,2013-06-14 00:58:46,315.47,,1,,"b'b"" Yeah", it can logically be viewed that way, but the implementation is a bit different because there\'s no way of having span ids influence the scala type. I created a special zero span that invokes identity when added to any span, and the plus operation just throws an assertion if the spans do not have matching id\'s. Mostly this is useful for some scalding jobs I\'m working on," but I think a second phase of this will be to go back and simplify some of the span aggregation code in the collector.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,260,closed,3,2013-06-14 00:58:46,319.88,,,1,"b'b"" Turns out we don\'t really need to do this.  It was a good exercise"," but not enough benefit.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,260,closed,closed,2013-07-17 22:17:33,1278.78,0,4,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,260,closed,reopened,2013-08-21 22:48:15,30.7,0,4,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,260,closed,closed,2013-08-21 23:24:42,36.45,0,4,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,260,closed,-,-,-,0,4,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,opened,2013-07-03 00:44:31,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,title,2013-07-03 00:44:31,00:00,,1,,"b""b' Add support for SQL databases'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,body,2013-07-03 00:44:31,00:00,,,1,"b'b"" The goal of this branch is to add support for SQL databases using Anorm from the Play framework. Note that I started by trying to do this with Slick instead of Anorm", but Slick depends on Scala 2.10 and it was too much scope creep to manage upgrading the whole project to be compatible with 2.10. This branch makes SQLite the default storage mechanism. There are now no setup steps -if you have Scala 2.9 installed and you download Zipkin, you can immediately run the daemons. Documentation for getting other SQL databases running is in  . Once this is merged, I\'ll look at using FuturePools to do the DB operations asynchronously," as well as adding Aggregates support.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,1,2013-07-03 00:44:31,736.73,,1,,"b'b"" What is the fancy new autoloading?  I\'m just curious.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,2,2013-07-03 00:44:31,597.48,1,,,"b""b' Also"," how hard is it to add Aggregates?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,3,2013-07-03 00:44:31,1.02,,1,,"b""b' Lastly"," please write some unit tests.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,4,2013-07-03 00:44:31,1126.53,,1,,"b""b' The path for  should instead be .'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,closed,2013-07-25 23:50:42,1386.18,1,4,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,reopened,2013-07-25 23:50:59,0.28,1,4,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,closed,2013-07-25 23:51:43,0.73,1,4,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,272,closed,-,-,-,1,4,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,opened,2013-10-28 09:34:44,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,title,2013-10-28 09:34:44,00:00,,1,,"b""b' cassandra issue'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,body,2013-10-28 09:34:44,00:00,,1,,"b""b' Zipkin runs on cassandra"," but cannot find traces with any specified annotation. The cassandra is setup with zipkin. Should any indexes be created?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,1,2013-10-28 09:34:44,437.9,,1,,"b'b"" I think that\'s a known issue.  I haven\'t had time to look into it. On Mon", Oct 28, 2013 at 2:34 AM," Linlin Fu notifications@ wrote:""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,closed,2013-10-29 15:00:46,326.03,0,3,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,reopened,2013-11-05 08:33:31,1052.75,0,3,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,2,2013-10-28 09:34:44,950.45,,1,,"b""b' The root cause is", in cassandra database, AnnotationsIndex stores RowKey with uppercase letters, but ServiceNames, ServiceNameIndex, SpanNames, ServiceSpanNameIndex use only lowercase letters. There are two solution, one is AnnotationsIndex uses lowercase letters, the other solution is ServiceNames, ServiceNameIndex, SpanNames," ServiceSpanNameIndex NOT convert to lowercase. Which solution is preferred from your perspective? I can make the change and send a pull request.'""",,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,3,2013-10-28 09:34:44,464.38,,1,,"b""b' Apologies for the slow reply on my part. Lowercasing the AnnotationsIndex would be fine by me. Thanks! /Johan On 5 nov 2013", at 00:43," Linlin Fu wrote:'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,4,2013-10-28 09:34:44,776.88,,1,,"b""b' Concur on lowercasing. '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,closed,2013-12-19 09:33:44,60.22,0,6,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,310,closed,-,-,-,0,6,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,opened,2013-12-16 23:13:56,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,title,2013-12-16 23:13:56,00:00,,1,,"b""b' highlight server duration on trace summary page'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,body,2013-12-16 23:13:56,00:00,,1,,"b""b' It is helpful to tell at a glance how network latency affected a trace.This change shows a highlight at the bottom of each span that containsboth client and server timings. The highlight shows what duration of thespan was spent in the server. I arrived on this highlight style after a few other attempts. It keeps thespan text readable and uses the color for the next depth (whichhopefully makes it more intuitive). Related to issue #196"," but probably not everything envisioned. ![example]url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,1,2013-12-16 23:13:56,986.58,,1,,"b'b"" This seems useful to me and not a big change  wise from what I can tell. I\'ll let someone that knows front end stuff chime in though.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,2,2013-12-16 23:13:56,143.75,,1,,"b'b"" Seems reasonable.  Perhaps we can trim the decimal precision down a bit though?I\'ll let @sprsquish chime in though.  What about making this a tooltip?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,3,2013-12-16 23:13:56,31.38,,1,,"b'b"" I played with this a little. I like the idea"," but think it needs a bit more. Having the extra line only gives a sense of what\'s happening but no real data is provided.  What about @bmdhacks\' suggestion of a tooltip? Add a little popover that provides the timing breakdowns?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,closed,2013-12-17 18:43:57,1170.02,0,5,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,reopened,2013-12-17 18:44:00,0.05,0,5,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,4,2013-12-16 23:13:56,27.0,,,1,"b'b"" I am not attached to the current approach and I\'m willing to try out other ways to visualize this. I do think that it should be readily apparent and not hidden in a tool tip (you can already click the span to see the actual timestamps). Inspiration from the Dapper paper: ![dapper example]url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,5,2013-12-16 23:13:56,3.0,,1,,"b""b' God I want that +thread expansion"," not the janky pseudo-intellijent fake-spans we have now.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,6,2013-12-16 23:13:56,704.28,,1,,"b'b"" @wadey what\'s your current thinking on this? @eirslett etc? I recognize this is over 1.5years old. should we pull this in or close it? (closing in 3 days unless I hear back)""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,7,2013-12-16 23:13:56,500.65,,,1,"b'b"" I still think this is a good idea"," but I need to re-do it in a way that makes sense for the new UI. I\'ll close this pull request and open a new one once I have done that (we are still running a very old version of Zipkin internally and we need to update to latest).""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,closed,2015-07-06 15:10:35,1226.58,0,7,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,8,2013-12-16 23:13:56,868.07,,,1,"b""b' ack. thanks for the response!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,319,closed,-,-,-,0,7,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,326,closed,opened,2014-01-15 22:08:03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,326,closed,title,2014-01-15 22:08:03,00:00,,1,,"b""b' zipkin storm: kafka spout and span scheme '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,326,closed,body,2014-01-15 22:08:03,00:00,,1,,"b'b\' This is to pave the way for zipkin storm jobs. A new project zipkin-storm is created to contain all the storm related sources. This pull request includes:1. span scheme to parse the steam data2. kafka spout to reading data from kafka queue3. sbt changes to create standalone jar ""zipkin-storm"" for storm job submission. \''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,326,closed,1,2014-01-15 22:08:03,20.82,,1,,"b'b"" Also I wouldn\'t mind getting somebody who knows storm to review this"," because I\'m only mildly aware of what I\'m looking at.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,326,closed,2,2014-01-15 22:08:03,1362.15,,1,,"b""b' lgtm. use the script in bin to pull submit'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,326,closed,3,2014-01-15 22:08:03,92.65,,1,,"b'b"" Hrm. Can you merge master? You\'ll probably have to fix the Project file.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,326,closed,closed,2014-02-06 01:36:03,208.0,0,5,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,326,closed,reopened,2014-02-06 18:08:43,992.67,0,5,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,326,closed,closed,2014-02-06 18:09:26,0.72,0,5,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,326,closed,-,-,-,0,5,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,opened,2014-07-05 16:50:07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,title,2014-07-05 16:50:07,00:00,,1,,"b""b' Keep sort order in hidden input'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,body,2014-07-05 16:50:07,00:00,,1,,"b""b' This patch enables zipkin-web keep sort order in hidden input. Without this patch you have to set sort order every submit.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,closed,2014-08-06 13:35:31,1245.4,0,2,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,1,2014-07-05 16:50:07,1399.8,,1,,"b'b"" @synk why\'d you close this? I like the idea and wanted to pull it in eventually and make some tweaks to it.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,2,2014-07-05 16:50:07,887.72,,1,,"b""b' Sorry to be confused...I will be glad if you pull this!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,reopened,2014-08-13 06:57:38,1042.12,0,4,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,3,2014-07-05 16:50:07,596.3,,,1,"b""b' Looking forward to this one!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,4,2014-07-05 16:50:07,1360.67,,1,,"b""b' @eirslett wdyt about this one?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,5,2014-07-05 16:50:07,2.57,,1,,"b""b' +1'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,6,2014-07-05 16:50:07,52.17,1,,,"b""b' oops. this patch no longer applies. @synk you mind rebasing it?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,7,2014-07-05 16:50:07,103.97,,,1,"b""b' closing as we want to keep the pull request queue fresh and relevant. Please ping if you get around to rebasing etc!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,closed,2015-07-17 18:13:18,675.67,1,6,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,395,closed,-,-,-,1,6,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,opened,2015-08-24 22:46:57,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,title,2015-08-24 22:46:57,00:00,,1,,"b""b' Cannot change port of the query service'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,body,2015-08-24 22:46:57,00:00,,1,,"b'b"" After this commit", it is no longer possible to change the port of the query service:url  Previously, you could do this to change the port: But this no longer works. From reading the source," it looks like this should work now but it doesn\'t work either:  ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,1,2015-08-24 22:46:57,1007.13,1,,,"b'b"" sorry it is a bit of a mess.. I\'ll look at this after catching up on change like url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,2,2015-08-24 22:46:57,760.47,1,,,"b""b' completely knackered"," but agree this is really bad. please nag on url  if this becomes critical and still left undone.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,3,2015-08-24 22:46:57,944.0,,1,,"b'b"" I\'m using the following workaround to make this work on my fork:url  It goes back to using the value set in the ZipkinServerBuilder.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,4,2015-08-24 22:46:57,29.4,,1,,"b""b' Looks like this was partially implemented as environment variables in collector like so Mind if I just implement that convention with COLLECTOR", QUERY," WEB?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,5,2015-08-24 22:46:57,5.45,1,,,"b""b' Yeah I like that idea"," that is how I am configuring our collector service. I have the following in my  config (which works with the above patch): I basically copied what collector was doing in its config.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,closed,2015-09-15 05:56:35,429.63,3,4,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,6,2015-08-24 22:46:57,1089.15,,,1,"b'b"" Thanks @adriancole! But your patch is actually incomplete and doesn\'t change the query port (try to change QUERY_PORT and see what happens). You need something like the changes I have for QueryServiceBuilder and ZipkinQueryServerFactory here:url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,reopened,2015-09-16 14:59:23,542.8,3,4,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,7,2015-08-24 22:46:57,111.17,,,1,"b'b"" Yep you\'re right! url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,closed,2015-09-29 18:06:42,187.32,3,4,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,8,2015-08-24 22:46:57,93.1,,,1,"b""b' should be good"," now'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,659,closed,-,-,-,3,4,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,opened,2015-09-19 16:12:43,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,title,2015-09-19 16:12:43,00:00,,1,,"b""b' Allow caching of getServices in the UI'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,body,2015-09-19 16:12:43,00:00,,1,,"b'b"" From @yurishkuro I think we should solve this at the HTTP abstraction", ex. sending cache headers back, so that the client doesn\'t call so much. There are two endpoints on zipkin-web that call  part of a massive thing that includes enumerating all services," to pass to  possibly unused json string list I see two things to do:change to use javascript to GET / and fill the selector by itselfchange to return cache headers""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,1,2015-09-19 16:12:43,1.23,,1,,"b""b' @mzagar @eirslett either of you have some cycles to help with this by chance?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,2,2015-09-19 16:12:43,817.2,,1,,"b""b' I believe I can take a look at this one.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,3,2015-09-19 16:12:43,16.85,,,1,"b'b"" Great. I suspect this won\'t impact you if you are only working inJavaScript layer. But just in case:url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,4,2015-09-19 16:12:43,31.87,1,,,"b""b' best to increase RF of the zipkin keyspace.(answers more to the availability than performance):+1: '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,5,2015-09-19 16:12:43,689.0,,1,,"b'b"" so realizing that the getServices isn\'t actually called by the javascript yet. Also"," I noticed a special case. WDYT about this? if  < 3 don\'t cacheotherwise set TTL on the http response to 30 seconds?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,6,2015-09-19 16:12:43,26.13,,,1,"b'b"" Isn\'t 30 seconds a bit low are new services created that often? I was thinking about adding a property allowing to set this timeout to a custom value at web startup and setting the default to 5 minutes"," is that too long? Optimization when not to cache sounds good. I\'ll make a PR fpr the js side later today. I noticed / was removed from available endpoints... should I put that back in?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,7,2015-09-19 16:12:43,2.2,,,1,"b'b"" Honestly I don\'t know what\'s the right value.. there\'s a special case ofbootstrapping"," which I think the minimum count would cover.. Perhaps 5mafter that is a decent value. Probably only way to find out is to spike it! Thanks for the offer for the javascript change! Note that ideally we\'dremove the call from  while at it.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,8,2015-09-19 16:12:43,59.08,,,1,"b'b\' @mzagar ""/"" can be put back in.. sure. We just want to remove the call in the  side once that\\\'s done. PS we had a chat on url  about wanting to do caching at the http-level", addressed by the browser. Browsers know how to deal with cache headers w/o creating special-caches in scala :) Best way forward is to do as much as possible to get the UI javascript-only. Put another way, a tactical scala cache just for services would probably end up as tech debt.\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,closed,2015-10-02 20:24:30,251.78,1,5,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,reopened,2016-02-17 01:34:04,309.57,1,5,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,9,2015-09-19 16:12:43,358.48,,1,,"b'b"" @yurishkuro @eirslett let\'s continue the chat from url  here"," as the history is here""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,10,2015-09-19 16:12:43,380.98,1,,,b'b\' To summarize status quo," the query server sends back a cache header when there are more than 3 services present: url  The actual age is assigned via the flag """"", which is incidentally not currently mapped as an environment variable. The zipkin-web server _should_ forward this header all the way to javascript (or any other caller). I suspect if it wasn\\\'t, @mzagar would have complained :P However, we have no test on zipkin-web to verify forwarding doesn\\\'t lose the header. The main reason is that zipkin-web is an older framework than finatra, and doesn\\\'t support feature tests.\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,11,2015-09-19 16:12:43,968.95,,,1,"b'b"" PS something Eirik mentioned was interesting. If 100s of service names strings are that slow", and for some reason HTTP cache headers aren\'t an option, a decorating SpanStore which caches in memory would be something those doing custom builds could add," if the middleware itself doesn\'t have a caching feature.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,12,2015-09-19 16:12:43,1006.37,,1,,"b'b"" We could add a cache layer with an environment variable to set TTL (default to 0 seconds", which disables the cache?)Ideally, people shouldn\'t have to do custom builds," if we can avoid it?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,13,2015-09-19 16:12:43,1007.55,,1,,"b""b' Another option is to deploy varnish as middleware on top of zipkin-query", to handle the caching. Then we only need cache headers," but the deployment becomes much more complex.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,14,2015-09-19 16:12:43,1079.07,1,,,"b'b"" I really think we should get most mileage out of the other cache setting wehave now (cache-control). If we find this is a fools errand", I\'d prefer weremove it and make a different parameter that works. one in-one out. In general I don\'t like the idea of doing in-memory caching in the queryserver. Guava and similar caches add more edge cases to the code, and inthis case," it is one api that sends very little data. What happens ifsomehow spanNames degrades in performance.. do we need another env property?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,15,2015-09-19 16:12:43,1381.67,,1,,"b'b"" We already did that a few months ago"," and I am still occasionally seeing the dropdown staying blank for a second or more after page loading. I feel it\'s a combination of transferring large JSON (via two hops due to query service running separately) and DOM creation altogether result in this visible latency. It just seems like the wrong design that the UI needs to keep re-loading this large list. Soon our list of services will be approaching a 1000.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,16,2015-09-19 16:12:43,117.77,,1,,"b'b"" I haven\'t tested the UI with 1000 service names yet. Might be worthwhile to stub the JSON API calls"," and measure the impact on DOM rendering time in isolation?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,17,2015-09-19 16:12:43,445.45,1,,,"b'b"" So", there are plenty of control and monitoring UIs with relatively stable things like buckets, application lists or tenants. I doubt that the supporting UIs require modification to the services they serve. Ex I doubt someone changed S3 bucket api to cache in support of AWS console, although S3 bucket list is quite a fast api anyway! I tend to see refresh buttons on UIs.. but I\'m sure there are other ways, too (ex buddy servers etc) Is there a way we can solve this lag problem without affecting the query server directly? I\'d prefer us to not have the maintenance of special-casing certain endpoints due to rendering delays," if at all possible.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,18,2015-09-19 16:12:43,1036.87,,1,,"b""b' I tried creating 1000 service names in the UI to measure the impact on rendering time: This basically replaces the API response with a list of service names", service0, service1, service2 ... service999.The impact on rendering time was minimal," there was no visual cue showing that the latency was higher than when rendering 15-20 service names.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,19,2015-09-19 16:12:43,199.85,,1,,"b'b"" We have hundreds of services here at pinterest and we see the lag in the UI dropdown being populated. So my experience is same as @yurishkuro\'s. Can we add an environment variable to set the ?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,20,2015-09-19 16:12:43,341.58,,1,,"b'b"" @mansu are you saying that your browsers aren\'t honoring the cache-control headers? or that you feel the timeout is too short?  Bear in mind that the UI is pure javascript and hits a normal http api. In other words"," cache headers can also be affected by nginx or similar normal web tier tech.  url ex. here\'s a caching option url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,21,2015-09-19 16:12:43,358.42,,,1,"b'b"" @mansu lol it is already configurable", just not documented  Here\'s the default, which is in seconds.  -max-age:300  This value can be overridden by system properties or any other [alternative supported by Spring Boot]url  For example," you can upper-case it as an ENV variable.  ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,22,2015-09-19 16:12:43,478.22,,,1,"b'b"" @adriancole ah"," that works also. Looked around for setting values via command line but couldn\'t find anything right away. Thanks!""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,718,open,-,-,-,4,13,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,opened,2015-10-20 22:26:36,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,title,2015-10-20 22:26:36,00:00,,1,,"b""b' AuthN Support'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,body,2015-10-20 22:26:36,00:00,,,1,"b""b' In our deployment of Zipkin", some internal customers are asking for authentication support, such that we can restrict the access on a per-service level. The reason for this is mostly that binary annotations may contain security-sensitive information. What I would be interested in is securing the query service via some form of auth," and then modifying web to prompt and forward that information. Thoughts?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,1,2015-10-20 22:26:36,72.93,1,,,b'b\' The terminates all traffic from the UI. One way to reduce surface area is to only expose  . There\\\'s work to do in order to lock that down, and bear in mind I\\\'ve not seen all things possible in finagle-land. is a [TwitterServer]url  and very similar to [Finatra]url  Most patterns of Finatra could be applied to  . To do authentication, you\\\'d likely end up writing a filter or explicit code. I\\\'ve found two examples:  [finatra-angular-example]url  and [finatra-tweet-example]url  The subject of authorization would be slightly more complex. There\\\'s a mix of responsibilities inside  , presumably folks optimizing for how much data is going to the browser, but honestly, I\\\'ve no idea. This mix presents itself as some javascript components calling json endpoints, and mustache template rendering doing other things. This scatters the authorization concern a bit," as if there was only a ""normal"" json query api", you could just secure that. For example, to authorize by service, code would likely need to wrap the underlying SpanStore object as that\\\'s the choke-point for data. The work involved in unwinding this problem is essentially refactoring the javascript UI to only use the query server\\\'s api. Authorization code could be much simpler, even at the http abstraction. That said, there would be a caveat, which is that you need to inspect the json to ensure a call to getTraces (by id) doesn\\\'t accidentally return data the user shouldn\\\'t see. That\\\'s because it isn\\\'t likely all storage implementations will be able to support transparent authorization. Regardless, once the UI only makes calls to a narrowly defined set of endpoints, you\\\'d have relatively straight-forward authorization. This would be whatever you can code in finatra, or any number of established patterns supported by [Spring Boot]url  such as [OAuth]url  (as [zipkin-java]url  is a boot app)\'',,,,,,,,,,,,,,,,,
zipkin,782,closed,2,2015-10-20 22:26:36,26.32,,1,,"b""b' All I can add to that is that", while securing the Java query server (and also collector now) will be very straightforward, you would probably have to write your own UI in order to deal with the user experience of being denied access (assuming authentication could be done as a separate service," which is fairly easy if you have one already doing oauth etc.).'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,3,2015-10-20 22:26:36,781.05,,1,,"b""b' Finatra being based on Finagle"," I imagine it would be possible to make some sort of a Filter to perform authentication and resource protection scheme but UI work would be needed and probably some way to model the security model.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,4,2015-10-20 22:26:36,220.92,,,1,"b'b"" Closing due to lack of activity. Zipkin is no longer based on Finagle directly", but on Finatra.I think you\'re left with 2 options: 1) put  in front of zipkin, to handle authentication (cannot be fine-grained)2) fork zipkin, to make a version with authentication support We\'re quite limited on resources," so I don\'t think autentication is something we would prioritise. (Feel free to reopenthis issue if any project members disagree!)""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,closed,2016-03-16 16:47:50,1101.23,1,3,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,reopened,2017-03-13 05:31:47,763.95,1,3,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,5,2015-10-20 22:26:36,781.7,,1,,"b'b"" Re-opening for @devinsba who has restarted an investigation on this (#1537). I\'m adding some notes to help frame thing", and thankful for the help.  The current topic is custom auth (also how any instrumentation might produce it). This will be easier for something like sleuth (as it uses the same language and library), so particularly important to consider non-jvm instrumentation, too.  To frame things, I think the idea is to understand what\'s sustainable and sensible to support wrt auth either directly (some auth module that covers all http), or indirectly (swap out http ui or collector for something secured). This is important as folks have different security contexts (some api key, some basic auth, some oauth). Also, afiak, the only http span reporters that support auth only do so because their underlying libraries do.  To set this up for success, I\'m pinging some folks who have custom http collectors for insight on what auth means for them (wrt at least collector, but perhaps ui if willing to share)  @trustin and @anuraaga (armeria collector) @marcingrzejszczak (some folks do [custom auth]url  in sleuth, presumably via custom servers?) @kevinmdavis @denyska (stackdriver zipkin) @nicmunroe riposte @pavolloffay hawkular  then other folks who have requested auth, but not on this thread, yet (at least @jquatier)  One thing of note is that while you can add transports to the zipkin-server (like sqs, etc), you currently cannot modify the http configuration. I think this is an artificial constraint, which we can likely change. For example, zipkin-ui autoconfiguration exists independently, so it should be possible to change UI authorization without affecting the http transport. However," it should also be possible to change the http transport for reasons including auth (ex performance which I know others have done in the past). ""'",,,,,,,,,,,,,
zipkin,782,closed,6,2015-10-20 22:26:36,197.82,,1,,"b'b""  That\'s more related to securing connection between Sleuth and Zipkin. What I think would need to be done here is more related to wrapping the  . In the you have the method which should be used to add tags. You could write an aspect or just provide your own implementation that extends the that would check some security details when somebody calls  .  Another approach would be to provide your custom implementation of the that would first e.g. remove the tags that shouldn\'t be there prior to sending them to Zipkin.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,7,2015-10-20 22:26:36,447.37,,1,,"b""b' So it seems there are 2 slightly different concerns here for people:  authentication: securing the webapp", including the span reporting endpoint authorization: securing the data from specific services to only certain users  Neither of these are straightforward as many orgs will have different ways of authenticating applications to each other and authorizing users  Securing the data seems to be more involved change though from securing the endpoints. As @dsyer noted, there are  implication to hiding data from certain users and showing it to others," and there is the question of what kinds of data can be hidden. @srijs maybe you can give more clarity to which types of things (tags? logs? certain ? entire spans?) you would like to have require authorization?  It seems to me that any authorization strategy will require authentication so these two components can be designed separately from each other as long as any design for authorization lays out its assumptions about what the authentication component will provide it'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,8,2015-10-20 22:26:36,114.02,,,1,"b'b"" Authentication during collection is probably pretty easy as long as the storage is only accessible from zipkin (a precondition for any authorization I think) SSL certificates work well for providing an identity in internal RPCs and seem to be the standard in linkerd", kubernetes, etc (I use it with armeria too for RPCs, though not with zipkin which I\'d rather be free as in beer ;) ). After that, it\'s just up to the data model to store this restriction some way a somewhat complicated way that doesn\'t require changing the model would probably be some binary annotation like (not really binary at this point...). The collector would validate this annotation against the provided identity (SSL certificate). The web UI could then trust this annotation to authorize when returning spans.  Authenticating and authorizing requests to a web UI tends to be more complicated if I was a Google Apps user I would expect authenticating to be Google Login Oauth and authorizing a lookup of Google groups. Other organizations might have different methods for employee authentication like LDAP. I guess the three components needed would be  1) What are the authorized parts of a span (specific annotations, entire span, etc) 2) Given a span-writing request, what\'s it\'s identity (pluggable, default could be SSL certs) 3) Given a request to the web ui, what identities can it access (pluggable," not sure of a good default)  Edit: I recalled vanilla zipkin might not support SSL I guess that would be a prerequisite to any work on security.""'",,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,9,2015-10-20 22:26:36,10.03,,1,,"b""b' For all who just need a simple oauth2 in front of zipkin web ui we used **nginx** + **oauth2_proxy**: url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,10,2015-10-20 22:26:36,1.52,,,1,"b'b"" SPIFFE url  could be a good fit here. If Zipkin supported the SVID  certificate (or even better", the SPIFFE Workload API) then it would (a) be able to automatically extract the service name from the certificate\'s SAN, and (b) would be able to use the associated PK to establish an mTLS connection to the Zipkin server. The SPIFFE infrastructure (eg. url  would automatically issue PKs to each client, and certificate bundles to the server," rotating them as necessary.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,11,2015-10-20 22:26:36,479.12,,,1,"b'b"" FYI", (and not about SPIFFE, rather related to a gitter chat)  We all have different ideas on what  needs to be, I\'d welcome folks to describe what they must have in order for this to be solved. Bear in mind that this may impact the http collector endpoint, but not others (ex kafka and rabbit have their own auth mechanisms). It is important to enumerate because we might end up otherwise burning time on a solution no-one can use and no sender supports.  TL;DR; mention what you need or want, and how if at all it impacts your apps (ex do your apps need to share a token or key or password? who manages these?). Mention any workarounds you use today," if you can. Appreciated!""'",,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,12,2015-10-20 22:26:36,254.55,,1,,"b'b"" For those who really really want basic auth and no proxy", here\'s a way to bolt-on BASIC auth to an existing zipkin server without modifying it.  Once you have it together," the below shows how to change password (though there\'s an example too) url This requires that you have maven installed. You don\'t need to do any custom code as it is 100% packaging.   Here\'s the only file you need:  ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,closed,2018-10-26 06:53:56,82.15,1,8,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,13,2015-10-20 22:26:36,1.95,,,1,"b""b' the above workaround was ported from earlier work by @devinsba .. thanks! url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,14,2015-10-20 22:26:36,901.63,,1,,"b'b"" @adriancole", we tested the auth configurations you recommended above and they work nicely but for only the GET APIs and WebUi however there are a issues with securing the POST APIs.  1. The zipkin server\'s POST APIs use undertow, so they are missed in the Spring Security configuration url 2. Clients cannot inject any auth headers, they only add content type url  3. ZipkinRestTemplate is package private so it would be a bad code smell to inject auth headers there.  Just a heads up for those interested in pursuing an auth approach. For the most part," there\'s no way to lock down POST without some sort of private network approach. Maybe the other transports Kafka or Scribe may have a way to auth writing.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,15,2015-10-20 22:26:36,947.42,,1,,"b'b"" You could deploy the POST servers separately from the GET servers", behind a network firewall," if that\'s sufficient?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,16,2015-10-20 22:26:36,1121.63,,1,,"b""b' RestTemplate is one of many senders. people customizing post likely use theOkHttp one from the zipkin-reporter-java project Also", we are moving the project to Armeria which has a customizer mechanismfor changing the server. When done, this could be used. In any case, like Eirik mentioned, you can use a proxy or something like pitchfork to separate out the collector tier On Tue, Jan 15,2019," 3:25 AM jbedalov <notifications@ wrote:>'""",,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,17,2015-10-20 22:26:36,469.12,,,1,"b'b""  @eirslett", yeah basically," that\'s what we will have to do. Thanks for the replies. ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,782,closed,-,-,-,1,11,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,opened,2016-01-28 11:01:54,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,title,2016-01-28 11:01:54,00:00,,1,,"b""b' How to track async spans?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,body,2016-01-28 11:01:54,00:00,,,1,"b'b"" So I think we\'ll need to think about async or background tasks a little bit more.At this moment if you have lets say Service A calling Service B and Service B using a background task to send an email", you can do two things: The second option is good UI wise, you can search for all those traces but you lose the connection to individual requests.The first option has the problem that if the background task is slow it looks like even ServiceA was slow. We have tried and even selecting by name or with filters in the UI, traces will always show fully and the total time be the time of the slowest. Ideally the solution would be to mark that those spans happening in the background are in fact background or async spans and that we do not want to count them for the calculation of how much the response took. The same solution would work for AJAX requests," which probably you do not want to compute them as the response time but still you want to have them connected to the request that originated them. Technically maybe is a binary_annotation added to the span to mark it as async and the server would need a bunch of changes. Do you think that is a good idea at all or it should be solved in some other different way? @dankosaur @dsyer ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,1,2016-01-28 11:01:54,148.05,,1,,"b""b' We recently had a couple discussions about this internally", and decided that the best approach for us is to treat background tasks as a separate trace," which contains the original trace Id as a  key.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,2,2016-01-28 11:01:54,210.33,1,,,b'b\' We have found that a separate span is a good idea (otherwise another background task started form the same span can look indistinguishable, or worse, overwrite the annotations of the first one). A separate trace is an interesting idea, but IMO shouldn\\\'t be the only option," because it really depends on whether logically the work done is part of the same ""job"" as the originating span or not.\''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,3,2016-01-28 11:01:54,39.65,,1,,b'b\' Agreed that a new child span in the parent trace is always a good idea.  Also agree that it\\\'s up to the application to decide is the background work should be a part of the same trace or not for us it\\\'s better as a separate trace, because the job can be queued and executed minutes after the main trace is finished, so merging them together creates various unwanted side effects, like the duration of the trace becomes all messed up, and the UI rendering is poor due to different scale. . capturing the parent, one idea that was discussed in OpenTracing was that capturing multiple parents of a span (e.g. via something like  ) can work not only for joins within the same trace," but also for the above use case of linking multiple traces. The root span of the background job trace will have the  ID of the ""separate span"" that you mentioned from the parent trace.\''",,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,closed,2016-01-28 17:39:56,398.03,1,3,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,reopened,2016-01-28 17:40:12,0.27,1,3,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,4,2016-01-28 11:01:54,492.7,,1,,"b'b"" let\'s see if we can nail a design down for zipkin v1 model here: #1243""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,5,2016-01-28 11:01:54,723.1,,1,,"b""b' related issue: multiple parents aka linked traces url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,925,open,-,-,-,1,5,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,opened,2016-01-29 16:38:14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,title,2016-01-29 16:38:14,00:00,,1,,"b""b' Relationship between CLIENT_SEND and SERVER_RECV annotations of spans'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,body,2016-01-29 16:38:14,00:00,1,,,"b'b"" I\'m working on AnormDependencyStore to fix some missing dependencies which have intermediate spans between RPC.For more details", see wip test url  Now, I wonder the relationship between CLIENT_SEND and SERVER_RECV annotations of spans.I surveyed several implementation and test spec but they varies. DependencyStoreSpec says cross service requests share a span.~~However, zipkin-tracer (Ruby) seems to be created new span on SERVER_RECV that is a child of CLIENT_SEND.~~And annotations reported by zipkinitself are no way. How should I handle implementation varieties? or Have I misinterpreted?Or it is not specified so should DependencyStore handle all possible patterns?### DependencyStoreSpec It  says cross service requests share a span.### zipkin Finagle?: url  Unless I\'m mistaken, it seems to be corrupted.### zipkin-tracer (Ruby)  SR: url  CS: url  ~~It creates new span on Server Receive.~~ **Actually it has the same output to test spec," OK.**### Go  SR: url  CS: url  [service1] Span0: SR[service1] Span1: CS[service2] Span1: SR It is the same to TestSpec.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,1,2016-01-29 16:38:14,20.37,1,,,b'b\' This topic comes up a lot. In zipkin," canonical spans come in two forms [""sr""","ss""] and [""cs",sr,ss,"cr""], depending on whether the client is instrumented or not. For example, zipkin (and dapper) examples usually do not have client-originated traces. So, the root span usually looks like  [""sr","ss""]. If there\\\'s an outgoing call, it would look like this  [""cs",sr,ss,"cr""]. The latter ""sr","ss"" annotations are contributed by the downstream services into the same span. We did throughly review the intent of the address annotations, which are documented here url  If you haven\\\'t seen this, have a look and let me know if there\\\'s any questions. No doubt that implementations (and spec data) have been out-of-sync. PS don\\\'t forget one primary trace instrumentation is .\''
zipkin	929	closed	2	adriancole	2016-01-29 16:38:14	0.45		+1		b""b' cc @jcarres-mdsol'",,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,3,2016-01-29 16:38:14,11.98,,,1,"b'b"" Thanks", I read thrift file firstly but I\'m not sure the server should start new span or use provided span id by Request Header," for SERVER_RECV annotation as the spec.Anyway implementations are varied...""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,closed,2016-01-29 17:11:02,32.8,2,2,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,4,2016-01-29 16:38:14,173.7,,,1,b'b\' Long story on that one ;) If the server has no propagated context Headers, it usually starts a newspan. If the headers are present," those ids are used. If a header says ""notsampled"" then no trace is created. Happy to chat more about this", too. Are you free to join the tracingworkshop Monday, Tuesday? We can review some of these things in a Tokyofriendly time. url \'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,5,2016-01-29 16:38:14,481.82,1,,,"b""b' The method in ruby is named terribly", it does create a new Span object in Ruby but it does not find a new ID for this span, so if your trace_id had the ids from the http request," the SR will send to zipkin a span with the same IDs than the CS which I think will work as per the spec'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,6,2016-01-29 16:38:14,167.12,,1,,"b'b"" Oh I see. You are right", I didn\'t checked method carefully.So as far as I know. the remaining problem is that default zipkin-web, zipkin-query and tracegen create obscurity annotations. OK, tracegen maybe misused CLIENT_SEND and CLIENT_RECV because they annotates it with  , not current  : url Should I open a pull request to fix? Also zipkin-web," zipkin-query may have another problem as explained above but it is not examined yet.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,reopened,2016-01-30 06:53:41,822.65,3,3,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,7,2016-01-29 16:38:14,9.37,,,1,"b'b"" Thanks"," the workshop is interesting. Maybe I have no time to join actively but I\'ll watch gitter.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,closed,2016-02-02 09:41:58,168.28,3,3,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,929,closed,-,-,-,3,3,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1074,closed,opened,2016-03-29 22:33:40,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1074,closed,title,2016-03-29 22:33:40,00:00,,1,,"b'b"" Don\'t distribute non-shadowed jars of collector-service and query-service""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1074,closed,body,2016-03-29 22:33:40,00:00,,,1,"b'b"" url  When people download the wrong jar", the UI assets won\'t be bundled (neither will any of the jar dependencies)I think @mansu had this problem, getting the wrong jar? (Or so it seems from the gitter conversation) If there\'s no good reason why we\'re publishing the not-shadowed jars, maybe we could just as well not distribute them in the first place? @abesto is it possible to configure Gradle so it doesn\'t build the jars, only the shadowed jars? (Or," at least doesn\'t upload the jars)""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1074,closed,1,2016-03-29 22:33:40,59.48,1,,,"b""b' I had this confused with url  today. :('""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1074,closed,2,2016-03-29 22:33:40,109.27,,1,,"b'b"" there\'s no use case for non-shadowed -service jars", so yes they can beremoved. aside: in the java project (zipkin-server), there is a use case, which isthat you can build a smaller or extended zipkin server (ex one that doesn\'tinclude kafka," or that includes 3rd party transports or storage).""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1074,closed,3,2016-03-29 22:33:40,1192.42,,1,,"b""b' Gave it a shot in #1076 (two commits because I found a better way"," so force pushed)'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1074,closed,closed,2016-03-31 07:33:53,540.22,1,3,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1074,closed,reopened,2016-04-01 02:28:32,1134.65,1,3,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1074,closed,closed,2016-06-03 08:58:59,390.45,1,3,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1074,closed,-,-,-,1,3,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,opened,2016-03-31 14:52:07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,title,2016-03-31 14:52:07,00:00,,1,,"b""b' move zipkin-sampler to its own repository'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,body,2016-03-31 14:52:07,00:00,,1,,"b'b"" The adaptive sampler is a storage filter who\'s goal is to keep collectors from overloading the storage layer. It does this by coordinating a sample rate based on the store rate of each member (against a target which the storage system is capable of). The adaptive sampler is implemented using zookeeper apis directly", using code that hasn\'t changed except for maintenance since imported. The code has a lot of classes, and had no notable tests until an attempt at backfilling last year in #891. The dependencies around zookeeper are troubling. Theoretically, one can install this as a filter on  , given some configuration. However, there\'s no instructions or known use in open source. That said, a version of this is used internally at Twitter. Options:remove it as it isn\'t used by the community at largepull the project out into a separate repository until people use or maintain itrewrite it using modern tools," reverse engineering its features and backfilling tests (~month of effort)""'",,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,1,2016-03-31 14:52:07,51.7,,1,,"b""b' +1 for moving it to a separate repository and add a short readme that explains what you just said.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,2,2016-03-31 14:52:07,424.8,,1,,"b'b"" +1 for moving it to a separate repository as long as we can still use it with mainstream zipkin.  I agree that the dependency on ZK is troubling", and we should fix it.  With that said, as far as I can tell it\'s the key feature that lets zipkin control its write traffic, which is what scaled it at Twitter," so I think it\'s worth keeping around in a usable capacity.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,3,2016-03-31 14:52:07,137.18,,1,,"b""b' Implementation aside", the integration with a span consumer is fairlysimple, a filter. This would work with both the scala and the java interfaces," and I can putexample code showing this.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,4,2016-03-31 14:52:07,70.45,,,1,"b'b"" One thing I\'d clarify is that even if I can demonstrate get this towork with another collection filter", this isn\'t a commitment in anyway to support it. There\'s no such commitment today by any currentcontributor of zipkin, nor any history of it by past committers. When this goes to its own repository, its fate will be in the hands ofthose interested enough to maintain several year old code," or thosewho wish to rewrite it.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,5,2016-03-31 14:52:07,926.42,,1,,"b'b"" Here\'s the issue that adds basic build infra url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,6,2016-03-31 14:52:07,440.67,,1,,"b'b"" Had an offline chat w/ @eirslett and I think it isn\'t worth it to move the sampler to a separate repository. Instead"," we can add support in zipkin-java and leave this here until zipkin-java can replace the code here. url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,closed,2016-04-18 01:03:20,611.22,0,7,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,reopened,2018-02-07 11:40:45,637.42,0,7,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,7,2016-03-31 14:52:07,638.02,1,,,"b'b"" No-one is using the zookeeper sampler. it has been just a maintenance burden for years. I\'d like to move it to openzipkin-attic  @ anyone disagree?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,8,2016-03-31 14:52:07,37.38,,1,,"b'b"" Are you sure Twitter is not using it internally? Maybe they\'ve moved off ZooKeeper?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,9,2016-03-31 14:52:07,0.88,,1,,"b'b"" they\'d only be using it directly if they moved to the java port of the server. In any case it isn\'t actually connected to the server"," so this is why I don\'t think anyone is using it.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,10,2016-03-31 14:52:07,1348.9,,1,,"b""b' +1 to move it to the archive.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,11,2016-03-31 14:52:07,5.17,,1,,"b'b"" @adriancole I\'ll talk to our zipkin team and get them to chime in.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,12,2016-03-31 14:52:07,66.77,,,1,"b""b' Thanks @mosesn if somehow this is in use", it is also ok to make it a non-attic repo (ex contrib)," just it pulls zk dependencies takes a while to run tests and has had near zero feedback for the last couple years. Would like to keep the core repo focused'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,13,2016-03-31 14:52:07,366.95,,1,,"b'b"" @adriancole let\'s archive it", if we (Twitter) want to use it we can maintain it.  We\'re using something similar but not this implementation today.  As a side note," we\'ve updated to 1.28.1.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,closed,2018-04-03 09:24:34,1303.82,1,12,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1078,closed,-,-,-,1,12,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,opened,2016-05-13 21:11:43,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,title,2016-05-13 21:11:43,00:00,,1,,"b""b' Display service name when showing addresses in the span detail element'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,body,2016-05-13 21:11:43,00:00,,,1,"b""b' Example screenshot:![image]url  Why: when a request comes from or goes to uninstrumented service", the instrumented part may log  annotations that include not only the peer IP address, but also the service name. However, the current UI, while it has a special handing for  annotations," does not display the service name.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,1,2016-05-13 21:11:43,193.95,,1,,"b""b' @adriancole are there unit tests for what gets displayed in the UI?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,2,2016-05-13 21:11:43,3.95,1,,,"b""b' yeap formatEndpoint has unit tests in  probably", just test that passing blank has the intended effect. Also I suspect the callsite needs to be updated to actually pass serviceName," right? Otherwise it is dead code.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,3,2016-05-13 21:11:43,122.88,,,1,b'b\' oh I remember this issue! We discussed and performed no action on this in the past. Last time we discussed this," we noted that having endpoint information for binary annotations isn\\\'t something we expect to carry forward in the model. Making a UI change to special case when multiple services report the same value formalizes a feature that will look ""missing"" when we finally get time to fix the model to disallow this. Next time you are raising an issue we have discussed and took no action on", please make reference to the former discussion and mention what has changed which would lead to us taking different action now.\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,4,2016-05-13 21:11:43,1.25,,1,,"b'b"" closing this as the issue itself hasn\'t changed url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,closed,2016-05-14 02:33:45,322.03,1,3,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,5,2016-05-13 21:11:43,95.1,,,1,"b""b' this PR is unrelated to that discussion. It is here to display service name normally encoded in ", which is otherwise hidden (LC had a special handling, which with this PR becomes unnecessary). The service name in the  annotations is respected in other parts of the code," specifically in the logic that derives a single service name for a span: url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,reopened,2016-05-14 04:21:29,107.73,1,3,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,6,2016-05-13 21:11:43,14.2,,1,,"b'b\' @yurishkuro you\\\'re right. re-opened and changing the title as this is related to ""address"" annotations", which are special-cased.\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,7,2016-05-13 21:11:43,22.48,,1,,"b""b' Ps can you put in a shot of the whole span detail element? It would beeasier to tell what the result looks like (ex if we are still consistent)'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,8,2016-05-13 21:11:43,301.58,1,,,"b'b"" ps I caused this to slow down", and am sorry about that. In repentance," I\'ll add the missing tests etc.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,9,2016-05-13 21:11:43,12.1,,1,,"b'b"" I would rather not show the parentheses at all if serviceName is empty"," isn\'t that better?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,10,2016-05-13 21:11:43,8.9,,1,,"b""b' @eirslett agreed'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,11,2016-05-13 21:11:43,49.68,,1,,"b""b' Added tests and a more complete screen shot. One glitch is that this causes the Annotations pane to show redundant info"," as it has service listed already... '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,12,2016-05-13 21:11:43,5.62,,1,,"b'b"" so I don\'t think this is shippable without revisions because it looks really chatty now. If this change was isolated to just the bottom part", or we took out the Service column in the top part," it would be shippable imho""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,13,2016-05-13 21:11:43,0.7,,1,,"b'b"" I guess another option would be to change the code so that it didn\'t apply to both sections.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,14,2016-05-13 21:11:43,9.55,,1,,"b""b' Yet anothet option could be to just add a service column at the bottom like there is at the top'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,15,2016-05-13 21:11:43,9.78,,1,,"b'b"" Added a commit with one option"," which is to make the top match the bottom. Here\'s a screenshot ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,16,2016-05-13 21:11:43,191.03,,,1,"b""b' LGTM!No strong opinions here. Leaving it as it is (showing the zero) indicates that Zipkin is indeed able to show which port a service answered on which can be handy for people to know", when they try to improve their  in more data. (port," in this case)'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,17,2016-05-13 21:11:43,48.1,,,1,"b""b' lgtm. Thanks for improvements & tests. I was porting this change from our pre-JS fork where it was only affecting the bottom part.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,closed,2016-05-15 00:17:12,1195.72,2,12,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1114,closed,-,-,-,2,12,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,opened,2016-06-14 09:10:52,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,title,2016-06-14 09:10:52,00:00,,1,,"b""b' Why did I fail to build the zipkin project?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,body,2016-06-14 09:10:52,00:00,,1,,"b""b' who can do me a favour please? ./mvnw  -DskipTests also-make -pl zipkin-server clean install[INFO] Scanning for projects...[INFO] [INFO] Reactor Build Order:[INFO] [INFO] Zipkin (Parent)[INFO] Zipkin[INFO] Zipkin UI[INFO] Guava support library[INFO] Storage[INFO] Storage: Cassandra[INFO] Storage: MySQL[INFO] Storage: Elasticsearch[INFO] Zipkin Collectors[INFO] Collector: Scribe[INFO] Collector: Kafka[INFO] Auto Configuration[INFO] Auto Configuration: Ui[INFO] Auto Configuration: Kafka Collector[INFO] Auto Configuration: Scribe Collector[INFO] Auto Configuration: Cassandra Storage[INFO] Auto Configuration: Elasticsearch Storage[INFO] Auto Configuration: MySQL Storage[INFO] Zipkin Server[INFO]  [INFO] [INFO] Building Zipkin (Parent) 1.1.5-SNAPSHOT[INFO] [INFO] [INFO] maven-clean-plugin:2.5:clean (default-clean) @ parent -[INFO] [INFO] maven-compiler-plugin:3.5.1:compile (default-compile) @ parent -[INFO] No sources to compile[INFO] [INFO] license-maven-plugin:2.11:check (default) @ parent -[INFO] Checking licenses...[WARNING] failure occured while calling class [WARNING] failure occured while calling class : Could not compute the year of the last git commit for file / at (:95)  at $1.load(:338)  at (:97)  at (:179)  at (:85)  at $2.run(:376)  at $(:511)  at (:266)  at $(:511)  at (:266)  at (:1142)  at $(:617)  at (:745)Caused by: : One of setGitDir or setWorkTree must be called.  at (:586)  at (:554)  at (:92)  at .(:75)  at (:138)  at (:84)  ... 12 more[WARNING] failure occured while calling class : Could not compute the year of the last git commit for file / at (:95)  at $1.load(:338)  at (:97)  at (:179)  at (:85)  at $2.run(:376)  at $(:511)  at (:266)  at $(:511)  at (:266)  at (:1142)  at $(:617)  at (:745)Caused by: : One of setGitDir or setWorkTree must be called.  at (:586)  at (:554)  at (:92)  at .(:75)  at (:138)  at (:84)  ... 12 more: Could not compute the year of the last git commit for file / at (:95)  at $1.load(:338)  at (:97)  at (:179)  at (:85)  at $2.run(:376)  at $(:511)  at (:266)  at $(:511)  at (:266)  at (:1142)  at $(:617)  at (:745)Caused by: : One of setGitDir or setWorkTree must be called.  at (:586)  at (:554)  at (:92)  at .(:75)  at (:138)  at (:84)  ... 12 more[WARNING] Missing header in: /-[WARNING] Missing header in: /-[WARNING] Missing header in: /-[INFO] [INFO] Reactor Summary:[INFO] [INFO] Zipkin (Parent) .................................... FAILURE [  0.922 s][INFO] Zipkin ............................................. SKIPPED[INFO] Zipkin UI .......................................... SKIPPED[INFO] Guava support library .............................. SKIPPED[INFO] Storage ............................................ SKIPPED[INFO] Storage: Cassandra ................................. SKIPPED[INFO] Storage: MySQL ..................................... SKIPPED[INFO] Storage: Elasticsearch ............................. SKIPPED[INFO] Zipkin Collectors .................................. SKIPPED[INFO] Collector: Scribe .................................. SKIPPED[INFO] Collector: Kafka ................................... SKIPPED[INFO] Auto Configuration ................................. SKIPPED[INFO] Auto Configuration: Ui ............................. SKIPPED[INFO] Auto Configuration: Kafka Collector ................ SKIPPED[INFO] Auto Configuration: Scribe Collector ............... SKIPPED[INFO] Auto Configuration: Cassandra Storage .............. SKIPPED[INFO] Auto Configuration: Elasticsearch Storage .......... SKIPPED[INFO] Auto Configuration: MySQL Storage .................. SKIPPED[INFO] Zipkin Server ...................................... SKIPPED[INFO] [INFO] BUILD FAILURE[INFO] [INFO] Total time: 1.268 s[INFO] Finished at: 2016-06-15T01:12:20+08:00[INFO] Final Memory: 20[INFO] [ERROR] Failed to execute goal :license-maven-plugin:2.11:check (default) on project parent: Some files do not have the expected license header -[ERROR] [ERROR] To see the full stack trace of the errors", re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions," please read the following articles:[ERROR] [Help 1] url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,closed,2016-06-14 09:11:16,0.4,0,2,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,reopened,2016-06-14 09:16:40,5.4,0,2,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,1,2016-06-14 09:10:52,67.53,,,1,"b""b' how to resolve this problem ?thanks!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,2,2016-06-14 09:10:52,1010.52,,1,,"b""b' ./mvnw :license-maven-plugin:formatin .'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,closed,2016-06-17 03:09:20,1072.67,0,3,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,3,2016-06-14 09:10:52,6.72,,,1,"b""b' thank you\\xef\\xbc\\x81'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,4,2016-06-14 09:10:52,371.83,,,1,"b""b' thank you!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1134,closed,-,-,-,0,3,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,opened,2016-06-24 03:43:01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,title,2016-06-24 03:43:01,00:00,,1,,"b""b' Why is the data lost in elasticsearch ?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,body,2016-06-24 03:43:01,00:00,,,1,b'b\' I used the zipkin, kafka, and elasticsearch for testing.  The elasticsearch was only a node. It wasn\\\'t problem that the data was transferred from kafka to zipkin, but the data is lost from zipkin to elasticsearch. I wrote 500000 log-data to kafka," but it was only 212162 in the elasticsearch. The data: ""ffffffffffffffff"" was replaced in ""1-5000000"";It was no regular!!!\''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,1,2016-06-24 03:43:01,98.82,,1,,"b'b\' there\\\'s a ""/metrics"" endpoint. It would show how many spans were accepted by kafka on the zipkin-server side.  can you send relevant output from that? also", I don\\\'t understand what you mean bydo you mean that when you post a span where the id is all bits set, it comes back not in hex?\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,2,2016-06-24 03:43:01,82.13,,,1,"b""b' I set id from 1-500000 in hex. I think that the index have a conflict.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,3,2016-06-24 03:43:01,8.17,,1,,"b""b' The lost data is different for storing in the elasticsearch  every"," when I wrote data in the kafka.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,4,2016-06-24 03:43:01,23.52,,1,,"b""b' wondering if this is to do with the data being older? Ex. if I post this"," I have to set lookback to a relatively high value to see it.  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,5,2016-06-24 03:43:01,111.88,,1,,"b""b' I started a local server against elasticsearch and got the same output. ex the trace id returned the same as if it were not using elasticsearch  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,6,2016-06-24 03:43:01,1.73,,1,,"b""b' @liangman we need some way of reproducing the problem"," so maybe verify versions and see if you can reproduce something using POST like above. Our tests run latest zipkin against elasticsearch 2.2.1'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,7,2016-06-24 03:43:01,188.92,,1,,b'b\' Ok," It is normal for using ""POST"""," but why is the data  lost for using ""kafka + ES""?\''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,8,2016-06-24 03:43:01,37.0,,,1,"b'b"" great... glad to see progress. First step is to make sure that whenyou say POST you mean POST + ES. That way", there\'s only one variablechanging, the transport. After you run your scenario, store thecollector metrics, which should show how many messages were sent, ifany were dropped etc. ex. url  url  Once you verify this, change only the transport variable and run thesame scenario (i.e. report using Kafka, not HTTP). look at the /metrics endpoint and compare the kafka stats with thehttp stats from the prior pass. you can also run the server with theargument commandline argument url  You might see dropped spans or dropped messages in the metrics output,"and you might see exceptions in the log output. This is how we canstart progressing from here.""'",,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,9,2016-06-24 03:43:01,760.78,,1,,b'b\' Of course," it was the ""POST + ES"";According to what you said"," I find that it has the same result.**kafka:**"""":100",""":1.0,"":4068.0,"":100,"":406770,"":-1,"":0}**http:**"":1569.0,"":100,"":1.0,"":100,"":156870,"":2.0,"":100,"":-1,"":0}And I run the zipkin with the argument  , but it is normal.\''
zipkin	1141	closed	10	liangman	2016-06-24 03:43:01	80.65		+1		b'b"" I had sent the same 100 data with kafka and http.**kafka + es**:paas@PaasAPMBootstrap:/$ curl -XGET \'129.188.37.108:9200/_?v\'health status index     pri rep   yellow open zipkin-2016-06-20 5 1    114    0  8.8kb    8.8kb **http+es**:paas@PaasAPMBootstrap:/$ curl -XGET \'129.188.37.108:9200/_?v\'health status index     pri rep   yellow open zipkin-2016-06-20 5 1    200    0   20.4kb   20.4kb ""'
zipkin	1141	closed	11	adriancole	2016-06-24 03:43:01	31.83	+1			b'b"" looking at your metrics output, it seems you aren\'t running the latestversion of zipkin ( should have read).I don\'t think this impacts your issue, but it would be less distracting touse the same version of code (latest is 1.1.5). One thing that seems odd is that the cumulative bytes collected fromhttp(157k)  are less than the cumulative bytes collected from kafka (407k).Are you using the same encoding for both? the byte count is after anydecompression, so I\'d expect figures to be similar... Regardless, if a scenario of only 100 spans can create the concern, itseems small enough to be something myself or someone else could run withease. do you mind posting your script somewhere so that I can try it?""'
zipkin	1141	closed	12	liangman	2016-06-24 03:43:01	16.1		+1		b""b' :  '",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,13,2016-06-24 03:43:01,0.82,,1,,"b""b' start_:  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,14,2016-06-24 03:43:01,0.65,,1,,"b'b\' ./start_ 101This is the script of ""post + kafka"".\''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,15,2016-06-24 03:43:01,4.85,,1,,"b'b"" I use the java for writing the data in kafka"," so I don\'t know how i post it. But I can write the script with the python. Please wait a moment.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,16,2016-06-24 03:43:01,2.67,,1,,"b""b' maybe you can send the same json you send via http using something likethis? url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,17,2016-06-24 03:43:01,40.0,,1,,"b""b' :  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,18,2016-06-24 03:43:01,4.6,,1,,"b'b\' Beause I remove the "" "" and ""\\\\n"" for sending to kafka. I think that you can try it with the script.\''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,19,2016-06-24 03:43:01,104.18,1,,,"b'b"" OK so I\'ve verified that with the following setup", I get readbacks between 58 and 100 spans when using the kafka script vs the http one which routinely reads back 100. what I do, is run the scenarios below while kafka is left up, but elasticsearch is cleaned between runs Where below instructions run kafka and ES And.. I start zipkin-server like so.. ### HTTP When I run the HTTP test like this: I get these collector metrics: And the api count looks correct: ### Kafka When I run the Kafka test like this: I get these collector metrics: And the api count looks correct sometimes," and not others (always the stats look the same):  ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,20,2016-06-24 03:43:01,6.38,,1,,"b'b"" NEXT STEP: one difference between in-memory storage and ES storage is that the former doesn\'t do anything asynchronously. We should validate that this scenario against Cassandra"," too (as it also uses guava futures).""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,21,2016-06-24 03:43:01,5.97,,1,,"b""b' en"," I will try it again following you step.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,22,2016-06-24 03:43:01,15.9,,1,,"b""b' Might be an issue in cassandra", too," but looks like #1142 is blocking my ability to use the normal readback (only returns 10-16)'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,23,2016-06-24 03:43:01,49.58,,1,,"b""b' No", when I send 100 data to the kafka," all data is written in cassandra. But I view 10 data from the page of zipkin. Maybe there is a bug in the code...'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,24,2016-06-24 03:43:01,6.55,,1,,"b""b' @liangman I edited the comment for the http script. can you edit the one for kafka and make sure that timestamps are reset each time (using epoch micros)?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,25,2016-06-24 03:43:01,42.77,1,,,"b'b"" NEXT STEP: See the behavior when the kafka script reports spans with unique timestamps. For example  . I don\'t really expect this to make a difference", but we ought to be consistent. A step after that would be to instrument in some way that we can track the futures (possibly ensuring the result has the correct numberOfActions() etc). This might be hard to track down, but at least the scenario is repeatable. ps I\'m offline likely the rest of the day," but might look into this tomorrow.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,26,2016-06-24 03:43:01,7.68,,1,,"b'b"" sure.. I\'d like you to edit your comment here url  in the span you are generating in python", please make it have timestamps according to current system time. That reduces the work needed when querying and also ttl considerations.  For example, you can look at how I edited the http script. url  after that you can try to troubleshoot ElasticsearchSpanConsumer by customizing the class, building and running locally. url For example, you could add print statements etc. If you aren\'t familiar enough to do that," you\'d likely need to wait until I have more time to help (or someone else does).""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,27,2016-06-24 03:43:01,42.12,,1,,"b""b' I have edited the script again. It may meet your requirements.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,28,2016-06-24 03:43:01,1049.5,,,1,"b""b' thanks. will take a look today On Sat", Jun 25, 2016 at 5:19 PM," liangman notifications@ wrote:'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,29,2016-06-24 03:43:01,265.95,1,,,"b'b"" Update: Adding a 100ms sleep between kafka messages seems to avoid this issue.. There\'s no errors"," but something seems to drop when processing concurrently.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,30,2016-06-24 03:43:01,3.98,,1,,"b""b' '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,31,2016-06-24 03:43:01,21.28,1,,,"b'b"" I\'ve found a workaround. This happens when a bulk request is used for a single request (only 1 span). When I special-case to not use bulk requests when there\'s only 1 span", the problem disappears. I\'ve two remedies:I\'ll adjust the code to special-case storage when only one span existsconsider sending more than one span per kafka message (note that @prat0318 notices this increases throughput anyway). We need to create a soak test at some point, too, as the special-casing may not be fixing the root cause," even if it helps. cc @anuraaga ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,32,2016-06-24 03:43:01,16.42,1,,,"b""b' @adriancole i am a bit confused. How come the way messages from kafka are read can affect something specific to ElasticSearch. If i am not wrong"," the flow will be kafka -'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,33,2016-06-24 03:43:01,114.3,,,1,"b'b"" I think http only worked because the test is slower. For example",sleeping 100ms in kafka loop also succeeded. TL;DR; I would recommend the bundling feature to anyone who seems likethey are writing tests or instrumentation. It isn\'t about this issuespecifically, more about encouraging supportable practice. Buffering and bundling spans ends up using(List...) as it was written to be used. At themoment, the only way to control the count of spans stored at a time byzipkin is to change the  to send more thanone span per message. I recall a discussion of adding a bufferinglayer internally to the kafka code, but that didn\'t go anywhere. We\'ve regularly encountered issues with not bundling across differenttransports and storage backends.. to the point where we changed thestandard format to be a list (the storage api was always a list evenin scala). You spent a lot of time learning that bundling helps a fewmonths back, but this isn\'t a c\\\\* only concern. ElasticSearch waswritten with the assumption that storing lists is the common case..else it wouldn\'t have used Bulk operations in the first place. This isthe same thing with MySQL and likely will end up the way for C\\\\* atsome point. We really ought to encourage bundling as a standardfeature for reporting spans regardless if the bundle size policy willbe transport-specific. The other option is to see a practice, like dumping many messages atthe same time, and say nothing. That person might go production etcassuming span-per-message is fine.. to a point where it is hard tochange their instrumentation. Maybe they never considered bundling atall. Would they have the experience and time you did to troubleshootand refactor late in deployment? Would someone be available for freeOSS support for several days? Would folks want to hack zipkin tobuffer on behalf of them? Would that debate finish quick enough andwith the desired outcome to resolve the issue? Maybe to all, but I\'drather raise a flag about a known stick then get smacked with itlater. Truth is, we can\'t count on volunteers to do free support, design anddev work on-demand.. so we have to work in ways that are likely to usethe limited time we have to help the highest amount of users. Whenfolks have bundling in mind from the beginning, it can be adjustedwhen they get into a support problem," or in their test scenario. Theycan solve or work around more problems without us.""'",,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,34,2016-06-24 03:43:01,20.37,,1,,"b'b"" here\'s the workaround.. when merged it should be testable from snapshot (of course if you are in a position to build the branch"," please do url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,35,2016-06-24 03:43:01,1056.98,,1,,"b""b' Ok", I have updated the file .  But when I set the count of log-data for sending the kafka," there is an Wranning here:  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,36,2016-06-24 03:43:01,7.55,,1,,"b""b' The result in the ES:  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,closed,2016-06-27 03:55:36,12.58,6,27,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,reopened,2016-06-27 03:57:50,2.23,6,27,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,37,2016-06-24 03:43:01,141.92,1,,,"b'b"" @liangman so let\'s first make sure we know what does work and what doesn\'t. Are you saying 100 works", but if you send 250 messages at the same time, you get that rejected exception? since the error includes a capacity of 200, again I\'m wondering what would happen if instead of doing 250 spans w/ 250 messages, you instead batched them as 10 or more per message (ex the json array includes 10 items not 1). ps here\'s the latest snapshot," if it helps url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,38,2016-06-24 03:43:01,46.52,,1,,"b'b"" Back to the error.. Right now the index queue depth is 200 and you\'ve overrun it. That means requests are being accepted faster than they can be processed. I think it will be useful to adjust the  count to see if you can make storage more efficient with the same topology. There\'s a lot of reasons it could be backed up", including the usual cpu, mem, network bottlenecks. It could be backed up from a slow cluster even.. We won\'t be able to troubleshoot what\'s the bottleneck in your environment, suffice to say you\'ve hit a limit. From an ES point of view," you can look at the tuning options there. Maybe start with this url  and run experiments until you\'ve found the key parameters that help.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,39,2016-06-24 03:43:01,1.7,,1,,"b'b"" FWIW", it is possible to adjust the default queue size through  or cluster settings if you needurl  ...though Adrian beat me to it ;) But as Adrian said, it seems like you are having issues with a highly-synthetic workload, not a real-world one. If this synthetic workload is important to you, then I\'d recommend trying to modify the cluster settings, but otherwise would recommend trying to send spans in batch instead (as the Java brave would). And keep in mind," Elasticsearch is IMO a medium-scale datastore. It\'s not going to get reasonable performance on a single node (this config is only for testing / development) and it\'s not unlikely you\'d run into perf issues with it.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,40,2016-06-24 03:43:01,103.87,,1,,"b""b' Maybe I have to consider changing the database from ES to cassandra. Because we forecast that there are at least 100 thousand log-datas to be sent to kafka per 1s in our micro service. So I will need a distributed Zipkin for consuming the data.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,41,2016-06-24 03:43:01,14.85,,,1,"b""b' When I use the cassandra for storing"," it spends about 100s for zipkin consuming 500000 data (per about 1kb).'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,42,2016-06-24 03:43:01,3.6,,,1,"b""b' Thanks for the update.. just curious"," was that with a single-node zipkinagainst a single-node cassandra cluster?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,43,2016-06-24 03:43:01,97.48,,1,,"b'b"" I\'m closing this issue for now as we\'ve progressed from no-errors and dropped data", to errors that explain why data was dropped (overran queue length)," and an ES storage config suggestion to improve that.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,closed,2016-06-27 10:45:32,407.7,7,31,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,44,2016-06-24 03:43:01,20.98,,1,,"b""b' ok.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,45,2016-06-24 03:43:01,38.98,,,1,"b""b' @liangman by the way"," _thanks_ your script allowed us to repeat the problem and convert it from a mystery to an explanation. The next users will be better off from your efforts.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,46,2016-06-24 03:43:01,1018.23,1,,,"b""b' I use the latest Zipkin(1.26) and with a single node elasticsearch(2.3.4) for storage(the default docker-zipkin configuration)", and still encounter data lost.  Here is the test script():  Then send 100(50*2) messages to Zipkin:  And some random messages are lost, I add  (introduced in Zipkin 1.25 ) environment to docker-compose-,  and saw these errors:   Check the default configuration:  [Change]url  to 500:  Then rerun the  script," there were no data lost any more.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,47,2016-06-24 03:43:01,1103.27,,1,,"b'b"" What you are saying is that when there\'s an overload on the elasticsearchcluster", zipkin drops data. The only recourse besides tuning ES would be tobuffer (or push-back if using kafka)," right?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,48,2016-06-24 03:43:01,1124.88,,1,,"b""b' Yes", at least Zipkin should log a  log if writing ES with errors returned while not setting  ," so we can monitor the log for alerting.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,49,2016-06-24 03:43:01,1194.57,,,1,"b'b"" logs and cause even more problems. Not sure this will be a good solution.Usually"," you\'d monitor for dropped messages or such by monitoring collectormetrics. logging failures at debug or trace may be fine either way. Notes on collector metrics:url  Example dashboard:url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1141,closed,-,-,-,8,34,9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,opened,2016-06-24 09:21:26,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,title,2016-06-24 09:21:26,00:00,,1,,"b""b' The limit problem'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,body,2016-06-24 09:21:26,00:00,,,1,"b""b' ![zipkin-pic1]url ![zipkin-pic2]url hello",when i query in zipkin-ui(the data storage in cassandra), if the limit param is 10 ,it shows Showing: 6 of 6 ;if the limit param is 20 ,"it shows Showing: 12 of 12;What is the problem?  Thank you!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,1,2016-06-24 09:21:26,7.43,,1,,"b'b"" Can you try using the http api like this (at the same time", which wouldreduce late arriving spans from skewing things)? $ curl -s \'localhost:9411/?serviceName=ycf-search&limit=10\'|jq. $ curl -s \'localhost:9411/?serviceName=ycf-search&limit=20\'|jq. The api always returns in descending timestamp order. looking at theoutput," you might be able to explain something..""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,2,2016-06-24 09:21:26,44.45,1,,,"b""b' I found it that if no request comes",when i query ,the number of the json will returns in descending timestamp order,Why?It looks strange,but if  storage in mysql ,"it will always return the correct number.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,3,2016-06-24 09:21:26,43.83,,1,,"b'b"" Not all Zipkin storage backends include arbitrary ordering capabilities.timestamps are a natural partition", as well something straight-forward tosort and apply further predicates to. In other words, it is implementable.Descending based on a timestamp provides more stable data than ascendingwhen we keep in mind that the default timestamp is now. (for example, ifyou using zipkin you are often responding to an issue vs clicking refreshuntil an issue occurs). The server-side sort order is a fairly well documented and tested part ofzipkin (other predicates directly apply given this is ordering assumption,including limit, duration etc). The good news is that you can assume itworks and report bugs if it doesn\'turl I\'d recommend using the api, and returning the json you mention that worksin mysql," but doesn\'t in cassandra. Even better if you can send a failingtest patch forurl ""'",,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,4,2016-06-24 09:21:26,275.25,,1,,"b""b' fwiw", I know exactly why LIMIT is not working correctly with Cassandra. In MySQL all the data is in one place, so however complex the query is, it is first satisfied against all AND clauses and then a limit is applied. With Cassandra, each AND condition may need to be resolved against a different index table, by doing direct shard key lookup. So instead of  , the Cassandra SpanStore implementation does  . The resulting intersection can easily produce < LIMIT results," quite often 0 if you have many AND clauses and LIMIT is small.'""",,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,5,2016-06-24 09:21:26,591.13,,,1,"b'b"" @yurishkuro You are right to mention the above when multiple conditions exist. We should document this somewhere besides the code", probably cassandra\'s README I guess. We should also make a failing test that we can skip in the cassandra module. All that said, I still think we need failing json for the issue as reported, because it isn\'t a complex query. Unless you know otherwise, it still seems unexpected to return less than limit when the query is simple, right? In the above screen shots, there\'s no query conditions except serviceName, and the cassandra logic appears to only use limit once.. for  . The (which gets the traces given ids) a different limit, a very large one  ," which defaults to 100000. Ex. here\'s a trace for a simple serviceName query in cassandra: ![screen shot 2016-06-25 at 9 19 32 am]url ""'",,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,6,2016-06-24 09:21:26,68.52,,,1,"b""b' Yes", making the LIMIT issue reproducable would be nice. On a simple query," I wonder if this is because the same trace ID gets returned multiple times. Most index tables in Cassandra allow dups of (search_key -'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,7,2016-06-24 09:21:26,30.4,,1,,"b""b' I think you may be onto something.. I think this is testable. For example",store RPC spans like they would arrive from instrumentation (server, thenclient). This would ensure that mid-tier spans would all have 2 span blobs.If this repeats the limit issue on simple query," we can test any remedy.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,8,2016-06-24 09:21:26,1.42,,1,,b'b\' for us to see this in json," we would have needed the ""raw"" queryparameter", as that would show separate span parts\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,9,2016-06-24 09:21:26,227.32,,1,,"b""b' so looks like I can reproduce this issue as it came up here url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,10,2016-06-24 09:21:26,53.5,,,1,"b'b\' Here\\\'s the summary of what I ""think"" is going on. The service_name_index needs will store only one trace_id per: (bucket", timestamp (millisecond), service_name) This means it can miss traces that happen against the same service in the same millisecond. @luoyongjiee can you check your data to see if this is the case?@yurishkuro @michaelsembwever @danchia can you verify what I\\\'m understanding above makes sense? I\\\'m able to reproduce this by issuing identical spans that vary only on ids and timestamps (ex in #1141). I use the following query to validate.  \'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,11,2016-06-24 09:21:26,612.97,,1,,"b'b"" Yep", sounds right," given  . Assuming they also hit the same bucket. Would\'ve been better with this key:  ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,12,2016-06-24 09:21:26,356.8,,1,,b'b\' In Cassandra primary keys: timeuuid should be used instead of timestamp.This avoids the problem of clobbering traces within the same millisecond. Regarding having to query individual partitions to get limits for each," this feature has been introduced in newer versions of Cassandra with the "" \\xe2\\x80\\xa6 PER PARTITION LIMIT x"" cql syntax.\''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,13,2016-06-24 09:21:26,77.0,,1,,"b""b' Agree that timeuuid is the typical pattern in cassandra for this. However", since the timestamps and trace_ids here are application assigned and cannot be changed," in my opinion it would be better to promote the field to the PRIMARY KEY as suggested by @yurishkuro '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,14,2016-06-24 09:21:26,136.35,,,1,"b'b"" @luoyongjiee update. I\'ve reproduced this problem in a unit test (important so it doesn\'t creep back in). Yuri\'s suggestion works fine"," but the index needs to be created. We\'ll have a release with the fix out by tomorrow.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,closed,2016-06-29 01:48:31,987.08,1,10,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,reopened,2016-06-29 04:41:21,172.83,1,10,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,15,2016-06-24 09:21:26,74.98,,1,,"b""b' Reverted 0d51d90 as it needs more work. We need the query to return only unique trace ids"," or repeat the query up to limit. Ex.  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,16,2016-06-24 09:21:26,62.47,,,1,"b'b"" so.. I\'ll wait for experts to get an idea.. I want to get  "," as opposed to a row for every span reported in the trace (often 2 rows per span). @michaelsembwever @yurishkuro @danchia rescue request :)""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,17,2016-06-24 09:21:26,514.95,1,,,"b'b"" I think this is the last update I have on this issue. always is higher than results from Cassandra queries", regardless of the schema adjustment we made (though the schema change does actually help with precision). That\'s because limit is applied to redundant index entries, which are deduped client side. The redundant index count is related to span count per trace. It is a fools errand to attempt to deduplicate trace ids on the (cassandra) server side because trace ids aren\'t a partition key. We can only do distinct clauses on partition keys. The only way left is to compensate on the (cassandra) client side: zipkin in this case. Here\'s two concrete proposals: ### Change CassandraSpanConsumer to cache trace id indexes locally By caching trace id indexes locally, we can ensure that at least in the same collector shard, we don\'t write the same unique input more than once per trace. This will be most effective for those who run a single collector or consistently route trace ids to collector instances. Even randomly routed collectors should see smaller indexes, when spans in the same trace are bundled when reported from tracers. ### Change CassandraSpanStore to fetch more trace ids than The trace id query returns very little data: trace id and timestamp. One option is to just prefetch more than limit and dedupe client side. Since this issue is amplified at low trace counts," we can simply make a floor of 100 and dedupe to  . This could be a first step before we do something like multiple expanding queries.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,18,2016-06-24 09:21:26,812.4,,,1,"b'b"" For the second remediation (fetch more ids)", I\'ve thought a lot and I think the best way is to have a multiplier. For example," fetch 10x more ids than you want (relates to how much variance in span data there is per trace). This is nice because system people can adjust it as they see fit and break the pattern of users always asking for more than they need.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,19,2016-06-24 09:21:26,119.85,,1,,"b""b' While in some sites it will need to be higher"," the lowest multiplier I could find that leads to unsurprising results is 3.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,20,2016-06-24 09:21:26,31.95,,1,,"b""b' final change in for this issue. will cut a release post-merge"," probably tomorrow  url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,closed,2016-07-10 01:21:13,1239.87,2,13,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1142,closed,-,-,-,2,13,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,opened,2016-07-28 12:20:33,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,title,2016-07-28 12:20:33,00:00,,1,,"b""b' Refactor duration queries in Cassandra'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,body,2016-07-28 12:20:33,00:00,1,,,"b""b' (from url  ) The following three tables can be merged into one. by using the following one table: Actual query constraints against a duration range would no longer be possible", but I suspect that doing this at run-time is not going to be worse than what we have today, especially if we can reduce so much writes," and put more read queries into the cache.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,1,2016-07-28 12:20:33,190.28,,,1,"b""b' love the idea of merging these.. I think that leaves us with only 2 indexes (to write to)"," which makes maintenance far simpler. nice work!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,2,2016-07-28 12:20:33,17.67,,1,,"b""b' That was the reason duration index was introduced in the first place. My users often run queries where  "," and the timeframe of the results it much less important than finding the actual long traces.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,3,2016-07-28 12:20:33,373.6,,1,,"b'b"" @yurishkuro I don\'t think this will be a problem though", because queries are still implicitly constrained by a time range. Either way I suspect there\'s still a lot to read and filter out at runtime," the real benefit here is to reduce the write amplification and to improve kernel filesystem and cassandra key cache hits. Further improvements beyond this tactic I think will need a look into  Materialized Views or SASI. SASI is an interesting one as it allows free-text searches on any column. But it is not available until Cassandra-3.4 ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,4,2016-07-28 12:20:33,17.15,,1,,"b'b"" Well", that\'s the problem, if my primary goal is finding long traces, applying a time range constraint first may produce no results. The duration index was duration constraint first," time range second.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,5,2016-07-28 12:20:33,4.27,,1,,"b'b"" I so wish github had threaded comments\\xe2\\x80\\xa6The implied time range is 3 days"," since we don\'t keep more than that already.How specific are your duration ranges? How many traces are already found within such?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,6,2016-07-28 12:20:33,6.7,,1,,"b""b' Duration query usually would be D '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,7,2016-07-28 12:20:33,49.92,,1,,"b'b"" Not sure I understand.  There is no LIMIT applied in the code today.Yes I can see this problem.My questioning and concerns is that this seems overly tailored to one installation and the user  knowing a value of so that cuts the query down to a more manageable number of columns to read through. If the default implied time-range is one day", then one third of the rows will need to be read.If one third of traces took longer than than one third of the rows will need to be read. In your particular situation I\'m curious about just how slow it\'s going to be to read through millions of columns. Along with trying to find a correct match between general UI behaviour and appropriate cql queries to be executing," I think this highlights the need to better stress test different scenarios and be working with some concrete numbers.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,8,2016-07-28 12:20:33,1089.93,,1,,b'b\' @yurishkuro while I see the goal, we neither document nor test the filter order you\\\'ve mentioned. Right now, it is the first N spans (looking back from a timestamp) that breach the duration threshold. Regardless of what we decide to do, we have to make it possible for this query to complete. Right now," it is a scar on zipkin as our ""recommended"" storage option includes a duration query that even if correct doesn\\\'t work. It is tiring to re-explain to every new cassandra user (that you cannot use the duration query). Its correctness only helps if it is usable.\''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,9,2016-07-28 12:20:33,4.88,,1,,"b'b\' by ""doesn\\\'t work"" I\\\'m referring to the the voluminous requests made with with current bucketing scheme+query plan that results in a long chain of requests that cannot complete (from here url  I\\\'d almost rather have no duration query feature vs a correct but unusable duration query feature\''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,10,2016-07-28 12:20:33,25.67,,1,,"b""b' I opened this PR", which should buy us time to address this change in whatever way ends up best. By switching the default lookback to 1hr," the existing implementation should be performant enough for us to make a non-hasty decision here. url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,11,2016-07-28 12:20:33,356.2,,1,,"b'b"" Thanks @adriancole for buying us time here. I agree with your sentiments.And I see @yurishkuro\'s need. It\'s going round in my head how we tackle this properly. I suspect the right way forward for us is SASI"," even though that means such functionality is not available unless Cassandra is running 3.5. In the short term with the lookback reduced to one hour I think we can go ahead with developing this patch. @yurishkuro will you be happy if I at the same time at this patch also develop a patch for SASI which I believe is more appropriate for your situation? (Will you be able to upgrade your Cassandra to 3.5 before you next need to upgrade your Zipkin?)""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,12,2016-07-28 12:20:33,86.3,,1,,"b'b"" @michaelsembwever don\'t hold on my account", we haven\'t even upgraded to the Java version of Zipkin, we\'re still running Scala build. However, since you mentioned SASI," would it make sense to reimplement _all_ indexing of Zipkin spans via secondary indices? The existing manual indexing doesn\'t work well anyway if a query contains clauses that must be resolved by different manual index tables today.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,13,2016-07-28 12:20:33,87.37,,1,,"b'b"" Yes that\'s the idea. I\'ll look into it.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,14,2016-07-28 12:20:33,1305.67,,1,,"b""b' Superseded by url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,closed,2016-08-24 00:36:09,735.6,1,14,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,reopened,2016-08-24 01:07:52,31.72,1,14,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,15,2016-07-28 12:20:33,33.25,1,,,"b'b"" I\'d prefer the changes to the old code to stay separate from adding a new model. It will keep review easier as there are some unanswered things here that would be burdensome to move to #1252. Hopefully"," the latter can just focus on adding the new model and therefore not need any changes from here.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,closed,2016-09-10 00:39:57,1412.08,2,14,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,16,2016-07-28 12:20:33,1411.27,,1,,"b'b"" cassandra3 is the answer to this. in other words", let\'s stop spending effort on the old one as when duration query is gone," it works well enough right now.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1204,closed,-,-,-,2,15,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,opened,2016-07-29 00:21:51,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,title,2016-07-29 00:21:51,00:00,,1,,"b""b' Search by dependency link'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,body,2016-07-29 00:21:51,00:00,,,1,"b'b"" One thing @yurishkuro mentioned in his presentation was that we don\'t support search by multiple services out of the box. This is interesting", because we do actually support search without a service. The use-case is moving from a link point of view (ex an edge on a dependency tree) to a trace query. We can investigate how search by service works on a per-datastore basis," as well the UI affects of such a thing.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,1,2016-07-29 00:21:51,568.48,,,1,b'b\' In microservice applications," searching among all services is really useful and required. Please consider to at least allow ""all"" keywords to indicate searching in all services.Btw", it would be great if simple regular expression is supported, such as xx*\\\\* in the -value search function. Thanks\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,2,2016-07-29 00:21:51,30.53,,1,,"b'b"" currently the api supports leaving out the serviceName parameter.url  regex isn\'t likely to work across all storage options server-side""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,3,2016-07-29 00:21:51,1381.38,,1,,"b""b' all service query is out in 2.3'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,closed,2017-11-13 09:22:15,540.4,0,3,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,4,2016-07-29 00:21:51,914.4,,1,,"b""b' @adriancole does this work in either of the Cassandra implementations? Looks like it might in v2 because of and SASI indices"," but v1 uses service name as a PK field iirc.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,5,2016-07-29 00:21:51,8.6,,1,,"b""b' as it does a fan-out across services.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,6,2016-07-29 00:21:51,4.68,,1,,"b""b' ah", fan-out, nice trick. Not an option for us," unfortunately (3k services).  thanks.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,7,2016-07-29 00:21:51,8.42,,1,,"b'b"" I\'ll raise a PR to minimize the impact of this for those usingcassandra and not yet upgraded.. If someone is just clicking search"," acheaper way is to scan the traces table until you\'ve collected enoughtrace ids.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,8,2016-07-29 00:21:51,108.73,,1,,"b'b"" actually"," we can\'t do this in the legacy impl because we don\'t haveany secondary index on the traces table (because we need to support2.2+ which has no SASI) Those who use cassandra and want more efficient all-services querywill need to upgrade I think... cc @ in case I\'mmistaken""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,reopened,2018-07-02 07:03:43,1301.47,0,8,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,9,2016-07-29 00:21:51,257.52,,1,,"b""b' re-opening as the root question was about searching by dependency link  url  is a design in progress'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1206,open,-,-,-,0,9,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1214,closed,opened,2016-08-02 16:04:06,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1214,closed,title,2016-08-02 16:04:06,00:00,,1,,"b""b' Relative time is incorrect in the UI (1.4.0)'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1214,closed,body,2016-08-02 16:04:06,00:00,,,1,b'b\' Hello," It seems the relative time displayed in the UI is off:![relative_time_issue]url  Though it seems correctly displayed:![trace_diplay]url  Here is the raw JSON to reproduce the issue:[{""traceId"":""1e223ff1f80f1c69""","name"":""post","id"":""74280ae0c10d8062","parentId"":""bf396325699c84bf","duration"":93576,""annotations"":[{""endpoint"":{""serviceName"":""serviceA","ipv4"":""},""timestamp"":1470150004008761,""value"":""sr""},{""endpoint"":{""serviceName"":""serviceA","ipv4"":""},""timestamp"":1470150004102338,""value"":""ss""}],""binaryAnnotations"":[{""key"":"",""value"":""b","endpoint"":{""serviceName"":""serviceA","ipv4"":""}}],""debug"":false},{""traceId"":""1e223ff1f80f1c69","name"":""get","id"":""bf396325699c84bf","duration"":99410,""annotations"":[{""endpoint"":{""serviceName"":""serviceB","ipv4"":""},""timestamp"":1470150004071068,""value"":""sr""},{""endpoint"":{""serviceName"":""serviceB","ipv4"":""},""timestamp"":1470150004170479,""value"":""ss""}],""binaryAnnotations"":[{""key"":"",""value"":""a","endpoint"":{""serviceName"":""serviceB","ipv4"":""}},{""key"":"",""value"":""200","endpoint"":{""serviceName"":""serviceB","ipv4"":""}}],""debug"":false},{""traceId"":""1e223ff1f80f1c69","name"":""post","id"":""74280ae0c10d8062","parentId"":""bf396325699c84bf","duration"":94539,""annotations"":[{""endpoint"":{""serviceName"":""serviceA","ipv4"":""},""timestamp"":1470150004074202,""value"":""cs""},{""endpoint"":{""serviceName"":""serviceA","ipv4"":""},""timestamp"":1470150004168741,""value"":""cr""}],""binaryAnnotations"":[],""debug"":false}] Thank you!\''
zipkin	1214	closed	1	adriancole	2016-08-02 16:04:06	660.03		+1		b'b\' the service names on your second span\\\'s annotations seem incorrect. They all say the same service (servicea). Your client serviceName should be different than your server serviceName, unless this is a loopback. You\\\'ll notice that the timestamp for your ""sr"" is before your ""cs"" (which means the server received a request before the client sent it!). I suspect you have clock skew. If you make sure your service names are different between client and server, zipkin will automatically correct the skew.\''
zipkin	1214	closed	closed	 - 	2016-08-07 03:04:08	660.03	0	2	1
zipkin	1214	closed	2	gboucher90	2016-08-02 16:04:06	337.1			+1	b""b' Indeed, thank you for your help!'",,,,,,,,,
zipkin,1214,closed,3,2016-08-02 16:04:06,38.48,,1,,"b""b' I tried with a modified json with correct service names"," though the relative time is still invalid.  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1214,closed,4,2016-08-02 16:04:06,41.05,,1,,"b'b"" The problem is that if the root span doesn\'t have any skew which is likely since it starts with only a local span  then the children don\'t get adjusted. ClockSkew skew = getClockSkew(());returns null for the root span and the processing stops""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1214,closed,5,2016-08-02 16:04:06,12.82,,,1,"b""b' Performing the clock skew adjustment even if the current skew is null works for relative time though the duration displayed in the UI is now incorrect.![duration_ok]url ![timeline_off]url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1214,closed,6,2016-08-02 16:04:06,889.33,,1,,"b""b' IP addresses have to be different for clock skew to make any changes. Itassumes if you have the same IP address you have the same clock.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1214,closed,7,2016-08-02 16:04:06,314.22,,1,,b'b\' Yes I did use a different set of IP,"127.0.0.0"" for serviceA and ""192.0.0.0"" for serviceB (see json or screenshots) Anything else I might be missing?\''
zipkin	1214	closed	reopened	 - 	2016-08-08 06:35:18	211.17	0	6	3
zipkin	1214	closed	8	adriancole	2016-08-02 16:04:06	18.68		+1		b'b"" We don\'t have any tests to cover a root span which has no client annotations. This could be a bug in the logic.""'
zipkin	1214	closed	9	adriancole	2016-08-02 16:04:06	2.55			+1	b'b\' basically, I posted the json to a local server and looked in the debugger. It seems the current code only starts thinking when there\\\'s skew visible in the root span. In the case of ""sr"" ""ss"" spans, you\\\'d not be able to know there\\\'s any skew. Hence, I think this might be a bug, especially as we\\\'ve no test case around this. We should fix this as ""sr"" ""ss"" spans are the most common type of root span!\''
zipkin	1214	closed	closed	 - 	2017-01-02 22:10:15	934.95	0	7	4
zipkin	1214	closed	10	gboucher90	2016-08-02 16:04:06	932.7		+1		b""b' Fixed in #1465 '",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1214,closed,-,-,-,0,8,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,opened,2016-09-05 09:18:08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,title,2016-09-05 09:18:08,00:00,,1,,"b""b' Error executing query: server error (parsererror) in Zipkin 1.8'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,body,2016-09-05 09:18:08,00:00,,1,,"b""b' I got when trying to find traces. This happens after update from Zipkin 1.7.0 to 1.8.2 today. Spans that I send are somehow problematic for the newer version of Zipkin. I get response every time. JSON:  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,1,2016-09-05 09:18:08,8.17,,,1,"b""b' thanks.. taking a look! On Mon", Sep 5, 2016 at 5:18 PM," Janusz Piech\\xc3\\xb3wka notifications@wrote:'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,2,2016-09-05 09:18:08,6.83,,,1,"b'b"" are the control characters in your json in the actual json itself? ex. I don\'t get an error from zipkin-server", rather one using a json parser. $ curl -s localhost:9411/|jq . parse error: Invalid string: control characters from U+0000 through U+001Fmust be escaped at line 2, column 1 On Mon, Sep 5, 2016 at 5:18 PM," Janusz Piech\\xc3\\xb3wka notifications@wrote:""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,3,2016-09-05 09:18:08,3.27,,,1,"b""b' yeah seems like it.. when I remove the control characters", the renderingworks fine. maybe we can scrub them at ingest... On Mon, Sep 5, 2016 at 5:33 PM," Adrian Cole @ wrote:'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,4,2016-09-05 09:18:08,2.83,,1,,"b""b' figured it out.. we need to do RFC 7159 escaping on ingest. will get thissorted shortly On Mon", Sep 5, 2016 at 5:36 PM," Adrian Cole @ wrote:'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,5,2016-09-05 09:18:08,5.08,,,1,"b""b' @adriancole You were so fast I was not even able to respond :D I will stick with 1.7.0 for now.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,6,2016-09-05 09:18:08,1.0,,1,,"b'b"" curious.. we aren\'t actually affecting  when writing.I think the library you areposting with is actually sending unescaped json. eventhough we need to fixhere", probably whatever\'s generating that will also need a nudge (so thatit doesn\'t produce values like this) On Mon, Sep 5, 2016 at 5:39 PM," Adrian Cole @ wrote:""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,7,2016-09-05 09:18:08,3.95,,1,,"b""b' @adriancole @nicmunroe I am using [Wingtips]url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,8,2016-09-05 09:18:08,6.15,,,1,"b""b' ok well lucky thing this change will fix both :) On Mon", Sep 5, 2016 at 5:49 PM," Janusz Piech\\xc3\\xb3wka notifications@wrote:'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,closed,2016-09-05 13:05:23,227.25,0,5,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,9,2016-09-05 09:18:08,191.62,,,1,"b'b"" thanks so much for reporting. I\'ve confirmed the fix by posting jsonmanually (as well unit tests). 1.8.3 on the way (and I\'ll also push a version of zipkin-reporter-java oncethis is out)""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,10,2016-09-05 09:18:08,2.07,,,1,"b""b' Thank you @adriancole! I will test the new version when it is out.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,11,2016-09-05 09:18:08,71.68,,,1,"b""b' ok it is out now!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,12,2016-09-05 09:18:08,17.72,,1,,"b""b' @adriancole Downloaded from and I still get this error with my JSON. Version 1.8.3'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,13,2016-09-05 09:18:08,34.5,1,,,"b'b"" :( I\'ll do the same and report back. I\'m literally  from the issue comments..""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,14,2016-09-05 09:18:08,8.08,,1,,"b""b' head scratching..'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,reopened,2016-09-05 15:21:05,135.7,1,7,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,15,2016-09-05 09:18:08,13.95,,1,,"b""b' ok this will teach me to switch between too many types of work. The change to fix every thing _except_ the problem you reported was merged. the fix for binary  was in a git stash. url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,16,2016-09-05 09:18:08,15.7,1,,,"b""b' 1.8.4 on the way. sorry about the confusion I created'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,17,2016-09-05 09:18:08,39.35,,,1,"b""b' Hahaha"," thanks @adriancole for checking this out again.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,18,2016-09-05 09:18:08,400.62,,,1,"b'b"" ok tested by downloading from maven and doesn\'t blow up!""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,19,2016-09-05 09:18:08,24.02,,1,,"b'b"" here\'s for wingtips url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,closed,2016-09-05 23:34:43,493.63,2,9,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,20,2016-09-05 09:18:08,175.23,,,1,"b'b"" @jpiechowka Merged", built," and deployed @adriancole\'s wingtips PR as wingtips version 0.11.1. Thanks guys!""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,21,2016-09-05 09:18:08,195.17,,,1,"b""b' awesome turnaround", nic On Tue, Sep 6, 2016 at 10:29 AM," Nic Munroe notifications@wrote:'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,22,2016-09-05 09:18:08,492.35,,,1,"b""b' Tested the new Zipkin version right now and it works well. Thanks @adriancole '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1272,closed,23,2016-09-05 09:18:08,565.05,,,1,b'b\' Whew :) thanks for replying back On 6 Sep 2016 15:47,"Janusz Piech\\xc3\\xb3wka"" notifications@ wrote:\''
zipkin	1272	closed	-	-	-	-	2	9	14
zipkin	1345	open	opened	mansu	2016-10-18 20:57:51
zipkin	1345	open	title	mansu	2016-10-18 20:57:51	00:00		+1		b""b' Automatically calculate and display network latency for a span in the UI'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1345,open,body,2016-10-18 20:57:51,00:00,,1,,"b""b' Currently", when we look at a span belonging to a trace in the UI, one has to mentally calculate the network latency to identify what percentage of the latency came from processing and what percentage of latency came from request processing. So, if a span has cs, cr, ss and sr," the network latency would be (sr cs) + (ss cr). Bonus points if the network latency can be shown like the chrome network latency tab. Adding an image from chrome documentation for reference. ![image]url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1345,open,1,2016-10-18 20:57:51,281.33,,1,,"b""b' This issue was moved to -ui#16'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1345,open,closed,2016-10-24 01:39:11,281.33,0,3,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1345,open,2,2016-10-18 20:57:51,0.3,,1,,"b""b' moved because there are similar concerns in the zipkin-ui repo'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1345,open,reopened,2018-10-26 07:45:09,365.97,0,4,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1345,open,-,-,-,0,4,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,opened,2016-10-26 08:06:43,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,title,2016-10-26 08:06:43,00:00,,1,,"b""b' handle cassandra pool busy'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,body,2016-10-26 08:06:43,00:00,,1,,"b'b"" When there are a lot of in-flight requests", we drop via a BusyPoolException. This notably happens in tests.   There\'s a discussion here about limiting the in-flight requests url Note: in our tests," we batch spans in 100 to avoid this.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,closed,2016-10-26 09:10:00,63.28,0,2,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,1,2016-10-26 08:06:43,78.9,,1,,"b""b' Problem with ?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,2,2016-10-26 08:06:43,375.32,,1,,"b""b' possibly! it takes 15m for every attempt to sort this in travis", and quite a fewvarious attempts done today, so not that interested in trying again. circleci is currently stable on cassandra with the extra configurationapplied to it. If that circle starts failing again," will get out the ulimitstick :) url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,reopened,2017-08-09 02:22:46,1032.77,0,4,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,3,2016-10-26 08:06:43,643.88,,1,,"b""b' reopened cc @ with a bit more in the description'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,4,2016-10-26 08:06:43,652.58,,1,,"b""b' There are some related notes in the recently announced v1.4 enterprise driver url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,5,2016-10-26 08:06:43,316.43,,1,,"b""b' Hey @adriancole we see a bunch of errors in our service log as such   '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,6,2016-10-26 08:06:43,641.75,,,1,"b""b' how are you expecting this to be handled?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,7,2016-10-26 08:06:43,1368.45,,,1,"b""b' We are using  to manage our docker containers"," zipkin ran fine for 15 mins or so -I noticed this issue is about **BusyPoolException** so ours not related.. will investigate (my guess we may need to consider tuning JVM). Thank you....!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,8,2016-10-26 08:06:43,1376.18,1,,,"b""b' busy pool would imply the cassandra pool is overrun. perhaps due to a surgeof spans. spans would be dropped in this case. not a cassandra tunerpersonally"," but I suspect increasing resources to account for spikes couldbe possible. could ask experts like @michaelsembwever'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,9,2016-10-26 08:06:43,125.58,,1,,"b""b' @adriancole I believe this issue is  related"," going to open a new issue. '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1356,open,-,-,-,1,8,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,opened,2016-12-16 03:06:11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,title,2016-12-16 03:06:11,00:00,,1,,"b""b' I have a problem about dependency and tree in zipkin UI'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,body,2016-12-16 03:06:11,00:00,,,1,"b'b"" I have get rest and mq span",then report the span to zipkin,"but it\'s not show dependency in zipkin UI and show tree no serviceName  ![image]url   ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,closed,2016-12-16 03:35:46,29.58,0,1,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,reopened,2016-12-16 04:07:26,31.67,0,1,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,1,2016-12-16 03:06:11,107.57,1,,,"b'b\' ""ms"" would have the endpoint of the local process"," not the remote broker(unless you\\\'ve somehow implemented the brokerThe messaging address(""ma"") will look exactly the same as how we handle theserver address (""sa"") ""binaryAnnotations"": [ {  ""key"": ""ma""","value"": true,  ""endpoint"": {   ""serviceName"": ""mq","ipv4"": ""127.0.0.1""  } }  ] there has been no code for messaging span, yet. so please onlyexperiment with annotations how they are described in the below pullrequest, but don\\\'t depend on it or expect any server changes untilthey are merged. url \''
zipkin	1439	closed	2	lijunyong	2016-12-16 03:06:11	56.27			+1	b""b' @adriancole Thank you,I will change the annotations,but why is black the serviceName in zipkin UI'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,3,2016-12-16 03:06:11,12.43,1,,,"b'b"" the UI interprets certain annotations. best to start with the correctusage", then if it is a still problem, ping back (don\'t expect the messagingones to turn out right since the UI doesn\'t know about that yet) On Fri, Dec 16, 2016 at 1:50 PM," lijunyong  wrote:>""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,4,2016-12-16 03:06:11,29.07,,,1,"b'b"" Thank you",what\'s the time to support \'ms\',\'ma\',"\'mr\' in zipkin UI""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,5,2016-12-16 03:06:11,13.18,,,1,"b'b"" shouldn\'t add UI until ppl are cool. Once it is merged"," it would be veryeasy to add to UI. (like days)""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,6,2016-12-16 03:06:11,11.95,,,1,"b""b' @adriancole thank you very much"," very nice'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,7,2016-12-16 03:06:11,204.3,,1,,"b'b\' if you use the ""cs"" ""sr"" practice of one-way spans", the UI should work properly," now. Here\\\'s an example url I don\\\'t expect us to continue with ""ms"" ""mr""\''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,closed,2017-01-16 10:20:57,373.52,2,2,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1439,closed,-,-,-,2,2,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,opened,2016-12-22 04:48:59,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,title,2016-12-22 04:48:59,00:00,,1,,"b""b' Hosting zipkin UI through a proxy'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,body,2016-12-22 04:48:59,00:00,,1,,"b""b' The zipkin ui that is hosted when a java zipkin server is launched is accessible only through the hostname of the machine where the ui is hosted. Like   If the request to the ui is proxied through a gateway", the UI becomes inaccessible. Like  The problem seems to be the bundle file for the ui is not requested relatively. The request is something like  , whereas this request should also be proxied  Looking into it, I figured that in file is specified as  , which makes the requests non relative.  Even after changing that, all the jquery requests that the ui makes to retreive the data is not proxied. Can this be changed, maybe accept a property in of the ui," which will allow the ui to be proxied? Or is there already a way to do this? '""",,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,1,2016-12-22 04:48:59,42.23,,1,,"b""b' assumption here is that you cannot deploy the UI assets to the proxy? exurl  On Thu", Dec 22, 2016 at 12:48 PM," raiRaiyan wrote:>'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,closed,2016-12-22 07:08:05,139.1,0,3,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,reopened,2016-12-22 07:08:11,0.1,0,3,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,2,2016-12-22 04:48:59,98.95,,1,,"b""b' @adriancole The ui itself is not accessible when proxied.  The  requests for a file non relatively. '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,3,2016-12-22 04:48:59,7.88,1,,,"b""b' oh right.. you are talking about proxying"," and also hosting under a different path.  can you please find the existing issue on this and close this as a dupe?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,4,2016-12-22 04:48:59,419.03,,1,,"b'b"" Ok", here is the solution we can implement (it was discussed before) Always serve the zipkin ui under a context path," like /zipkin/. Any requests that don\'t start with that URL will automatically be forwarded. That means there will be no special handling when using a proxy.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,5,2016-12-22 04:48:59,5.95,,,1,"b'b"" @eirslett seems right", since iirc most are asking for that specific path anyway :) We\'d have to whitelist quite a few things, like the api config health checks," etc. Maybe we forward the root itself or is a whitelist ok?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,6,2016-12-22 04:48:59,1.85,,1,,"b""b' /api/ can be duplicate-served under // for a while"," I guess not all http clients people use handle 302? But all browsers will.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,7,2016-12-22 04:48:59,41.27,,1,,"b""b' @eirslett what if we did it the other way.. we change the content to use paths of /zipkin", and mount the UI assets both under /zipkin and also under root. Might be naive," but could that solve the migration problem as well? cc @abesto '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,8,2016-12-22 04:48:59,70.28,,1,,"b'b"" The problem is with crossroads"," which doesn\'t know what to serve (which route) if it doesn\'t know about the context path.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,9,2016-12-22 04:48:59,1217.0,1,,,"b""b' dupe of #1229'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,closed,2017-06-23 12:33:26,325.25,2,8,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,10,2016-12-22 04:48:59,399.13,,,1,"b'b"" @adriancole i ran into a similar issue recently. If I hit Zipkin host from a proxied host", e.g. url  it\'ll redirect me to  . But if I hit the context root," then it\'s loads fine.  Is there any chance to redirect to context w/ relative URL?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,11,2016-12-22 04:48:59,709.0,,,1,"b""b' Is there any chance to redirect to context w/ relative URL? Possible. Can you weigh in on url and open an issue about relative url if not ok. There are a few issues likethis and want to reduce any overlap complexity Cheers!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,12,2016-12-22 04:48:59,177.37,,,1,"b""b' I was able to make it happen with Zipkin latest version", 2.5.3, using \\xe2\\x80\\x9c\\xe2\\x80\\x9d. I have Zipkin behind Zuul, with service discovery working like a charm. In my Zuul routes I have mapped Zipkin to \\xe2\\x80\\x9c//**\\xe2\\x80\\x9d, pointing to \\xe2\\x80\\x9czipkin-service\\xe2\\x80\\x9d as registered in Eureka and at Zipkin YML config," my \\xe2\\x80\\x9c\\xe2\\x80\\x9d points to \\xe2\\x80\\x9c/\\xe2\\x80\\x9d. With this settings I can run for \\xe2\\x80\\x9curl \\xe2\\x80\\x9c and all redirects works. Hope it help another people. Passed two days figuring out what to do...'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,13,2016-12-22 04:48:59,693.75,,,1,"b""b' thanks so much for sharing!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,14,2016-12-22 04:48:59,163.53,,1,,"b""b' hi@brunouska  how are u accessing zipkin thru serviceid or url.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,15,2016-12-22 04:48:59,244.6,,1,,"b""b' @momentum123"," I\\xe2\\x80\\x99m accessing zipkin by Zuul exposed url. Zuul uses Service id at route mapping.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,16,2016-12-22 04:48:59,324.12,,1,,"b""b' @brunouska  i have tried the same but doesnt work for me tried on earlier version and 2.5.3 and on 2.7.1 doesnt work on any of them please tell me if im doing something wrong and given that im setting the property on jar invocation : java -=/ -jar  setting property =/    accessing thru gateway  url getting same broken ui without any changes url  i have tried a workaround in  #1993  works partially: [ui]url   '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,17,2016-12-22 04:48:59,78.97,,1,,b'b\' Let\\\'s go @momentum123,  My Spring Boot Version for my implementation is 1.5.9.RELEASE My Spring Cloud Version for my implementation is Here\\\'s my Zuul routes config," at my YML:  zuul: ignored-services: ""*"" prefix: /api routes:   trace:   path: /tracing/**   serviceId: bahauser-trace-server  Here\\\'s my Zipkin Config", at my YML:  eureka: instance:   lease-renewal-interval-in-seconds: 5   instance-id: ${}:${:${:${}}}   prefer-ip-address: true client:   registryFetchIntervalSeconds: 5   region: default   service-url:   defaultZone: url {bahauser-discovery-}:${bahauser-discovery-}@${bahauser-discovery-}:${bahauser-discovery-}/eureka/  zipkin: ui:   basepath: /  When accessing Zipkin thru Zuul," i use ""url """," note the ""/"" at the end", you have to put it in order to access the UI. You can handle this with a redirection if you want it, at my needing this not a issue. Try with this settings.  You can not get it working we could make a git repository only with the modules involved. I have so many other things, like rabbitmq, auth, so on... If you can not get working I put something at Git Hub for you.  \'',,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,18,2016-12-22 04:48:59,81.57,,1,,"b""b' This was a little tricky for me to get working"," pay attention to the minimum details at your configuration.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,19,2016-12-22 04:48:59,986.85,1,,,"b""b' sorry for the really late reply. thanx the above solution worked like a charm for me'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1452,closed,-,-,-,3,13,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,opened,2017-01-15 22:17:17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,title,2017-01-15 22:17:17,00:00,,1,,"b""b' Implementing Collector for Azure EventHub'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,body,2017-01-15 22:17:17,00:00,,,1,"b""b' Hi","  I am [working]url  on a Zipkin collector for Azure EventHub. The work itself is not demanding since most of the heavy lifting is done by the Azure Java SDK itself. However I am not sure if I should contribute as part of Zipkin itself or it is able to load plugins and configurations from outside.  Can you please guide what is the best route?  Thanks '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,1,2017-01-15 22:17:17,170.02,,,1,b'b\' Thanks for the ping, Ali! We sometimes get people asking about variousaspects of azure. Exurl  forstorage There are two alternate collector projects: url  < for amazon components, notableSQSurl  <actually morea storage bridge to Google Stackdriver on SDK vs small internal library Zipkin-aws uses the Amazon SDK to access SQS, though that may not always bethe case. There are pros and cons to using an SDK for something likepulling from a queue. For example, usually the SDKs have quite a lot ofdependencies, and the act of pulling from a queue is a simple rest call.Moreover, the rest calls involved in collections are usually extremelystable apis. Additional dependencies can often complicate interactions withexisting code, and they typically not easy to instrument," for exampleinternal debugging we call ""self-tracing"". On the other hand", sometimesSDKs are directly integrated in Spring Boot, which could cut down work.Also, SDKs often help with platform-specific concerns. For example,Amazon\\\'s includes the ability to refresh credentials which is nottechnically difficult, but work better deferred until it has to bechanged.  In the zipkin-aws project, code currently seems better off usingAmazon\\\'s SDK than not, so that\\\'s why it does! back to the point.. Anyway, when making a zipkin-azure, I\\\'d make the SDK an internal detail, incase it needs to change later, and follow the same pattern as zipkin-aws asthat\\\'s almost exactly the same interaction you\\\'ve mentioned. You canprobably ping @llinder for advice, too. In both projects mentioned, there\\\'sa separate docker image at the moment," though we\\\'ve regularly discussed a""layer"" approach which could make it possible to add something like AzureEventHub to an existing container. next steps (imho).. The key next steps would be to look at the existing projects", and introduceyourself in gitter, as that\\\'s where we chaturl Then, decide whether you want to make this third-party or not. For example,zipkin-aws is released in the openzipkin org, which means a few of us canrelease it. Outside the zipkin org, you would be responsible fordetermining your own path, for example, Google have their own continuousintegration and release setup (which seems to work well). Regardless, you\\\'dwant to make sure that there\\\'s some user who can vet that the result works.For example, one common problem with new code is that it is only used bythe author. If you find a user or another stakeholder, the work will bemore sustainable. Hope this helps!-A\''
zipkin,1488,closed,2,2017-01-15 22:17:17,5.18,,,1,"b'b"" ps totally missed that there was a link in your description!url  cool that the collector work is in progress. If I were you", I\'d try toadd offline tests to it (this allows others to help even if they don\'thave a cloud credential). We often use MockWebServer to do things likethis," though google created a fake server of their own (since it wasmore gRPC than plain http). The key would be getting the SDK to allowyou to override the URL to azure so that you can fake responses.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,3,2017-01-15 22:17:17,5.02,,,1,"b""b' I pinged twitter to hopefully interest others in contributing or helping url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,4,2017-01-15 22:17:17,474.43,,,1,"b""b' @adriancole Awesome mate! That is excellent. Thanks I believe I have all I need. As you can see", it is only the skeleton with no embellishment, etc. As you might have guessed," Java is not my primary language but I will make the effort to ensure this is of the quality rest of zipkin is akin to.  I will close the issue but I might get back to you soon.  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,closed,2017-01-16 09:11:56,654.65,0,1,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,5,2017-01-15 22:17:17,10.65,,,1,"b""b' looking forward to it!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,reopened,2017-01-18 22:35:16,803.33,0,1,6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,6,2017-01-15 22:17:17,799.22,,1,,"b""b' OK", I have made progress and trying to get it run. I know this could be a silly question but I am new to all this: how is zipkin-aws supposed to run for example? My expectation for zipkin-collector-eventhub is that I drop zipkin-collectoralong with the zipkinand run the zipkinand specify configurations in  or  and the Spring Boot autoconfig will load it and start running my host in addition to zipkin-server. But I have not been able to get this to work. Do I need to make my jar a Spring Boot application," like  ?  Can you please provide some pointers?  Thanks a lot.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,7,2017-01-15 22:17:17,281.57,,,1,b'b\' hi, @aliostad Thanks for the update.  Right now, people are working with custom images," though there is a means to change how things work by using ""zip"" layout on the server", which allows use of the more customizable [property launcher]url There\\\'s another approach, too, a thin launcher.. I mention things about it here: url It is high time we had a suggested and testable way to compose server binaries.. let\\\'s follow-through on this.\'',,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,8,2017-01-15 22:17:17,859.03,,,1,"b'b"" @aliostad to answer the question about how I do this with zipkin-aws.  Right now we make a fat jar by depending on zipkin and our extra auto configuration libs.  From there we create a new layer on the zipkin docker container by exploding the fat jar in the same way the upstream build does.  This is  fairly easy though it does make the container larger than needed since the old layer still remains.  Ideally we need to figure out an elegant way to only layer in new jars.  Both the property launcher and thin launcher sound promising though I don\'t have experience with either so I\'m anxious to see what the developer experience would be like.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,9,2017-01-15 22:17:17,932.35,,,1,"b""b' @llinder Hi", thanks for the comments. So this fat jar," what script gets used to build this? I would like to see what the process is.  This weekend I will spend some time getting my head around thin launcher.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,10,2017-01-15 22:17:17,21.38,,1,,"b'b"" I don\'t think this exists in zipkin-aws at the moment.. there is aversion of what was originally to be merged here: url  the spring-boot-maven-plugin makes the fat jar","'
zipkin	1488	closed	11	aliostad	2017-01-15 22:17:17	706.35		+1		b'b"" OK I have been looking into samples of thin launcher. I cannot see any ZIP layout so properties can be changed, am I missing something or we can configure thin launcher in other means?  ### [UPDATE]  I finally got zipkin-server to read  using  . So I guess I don\'t need any magic for supplying config as I can use the same trick.""'
zipkin	1488	closed	12	adriancole	2017-01-15 22:17:17	510.0		+1		b""b' actually, the thin plugin is available, you just need to use snapshot repo  ex. url '",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,13,2017-01-15 22:17:17,274.8,,1,,b'b\' Update: figured out how to get modularity working. It is a little constrained, but it works now.  Here\\\'s how.  ## Step 1: Add spring boot plugin to your autoconfig module," adding a ""module"" jar  The classifier name ""module"" is arbitrary", but I think it works. Take extreme care to not duplicate jars already in zipkin-server\\\'s exec jar. Here\\\'s an example configuration for the SQS collector:   This will make a file like..  ## Step 2: Extract this module jar when composing a server layer  I cannot get the PropertiesLauncher configuration to accept the module-jar directly. However, the following does work.  1. extract your module jar somewhere (Ex to an extensions folder) 2. explicitly start zipkin using with set to include that directory  Example:   Note: the module jar is self-contained.. when doing your devopsian things, feel free to just curl it from jcenter, like we do for the server jar.\'',,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,14,2017-01-15 22:17:17,193.35,,,1,"b""b' Wow! @adriancole that is so nice! Thanks a lot. I will hopefully get to play with this today or tomorrow.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,15,2017-01-15 22:17:17,411.27,,1,,"b""b' So unless I am missing something", this is not launcher," no? So do you think it is worth to try that out (I was trying to get my head around it and made some progress) or this is the canonical way to go (using MODULE to create a fat jar)?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,16,2017-01-15 22:17:17,281.78,,,1,"b'b"" using a modularity feature that\'s been in spring boot for a whileon it finishing or us :) There\'s also matters like docs support etc whichare trickier on experimental features. I\'d say that the best way forward for today is to use the module approach",and then have an experimental (or even alternate docker image) for the thinlauncher. In other words, module for tactical and short term," and thinlauncher as an experiment (possible future replacement) my 2p""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,17,2017-01-15 22:17:17,488.65,1,,,"b""b' Thank you. I will carry on with this. Do I need to define (was not in your configuration above)? Here is what I get:   And if so","  I guess it should be from zipkin-server?  Using works but does not load my stuff.  PS. Sorry for asking many questions... I am actually pleased I have made it this far. With little background soon will be publishing my contribution \\xf0\\x9f\\x91\\x8d '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,18,2017-01-15 22:17:17,14.17,1,,,"b""b' @aliostad so keep in mind this is using the default zipkin exec jar (which has the start class). You would be making the module that adds to it.  Ex. you should be able to download and use an unmodified zipkin-server jar like below.. (which was  in my example)  url also feel free to hop on url  if you get stuck! Thanks for the help on this'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,19,2017-01-15 22:17:17,144.63,,1,,"b""b' Sure", I will go to gitter. Just to clarify I WAS using the original  but as I said," it was not working with  .'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,20,2017-01-15 22:17:17,780.2,,,1,"b'b"" somewhere)", and add instructions for how you get the error. Then," myself orsomeone else could try. It might be better than guessing what\'s up""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,21,2017-01-15 22:17:17,446.63,,1,,"b""b' OK", this is working now \\xf0\\x9f\\x91\\x8d Impossible without your help. I am closing this now," I have everything I need.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,closed,2017-01-26 08:27:58,592.7,2,9,12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,22,2017-01-15 22:17:17,21.98,,,1,"b""b' vetting ideas on how to do modularity!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,23,2017-01-15 22:17:17,41.07,,,1,"b""b' I am pleased this helped pushing for better modularity! It looks awesomely clean yet pluggable.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1488,closed,-,-,-,2,9,14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,opened,2017-04-16 02:31:46,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,title,2017-04-16 02:31:46,00:00,,1,,"b""b' trigger cassandra page fetch failure'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,1,2017-04-16 02:31:46,24.52,,1,,"b""b' If this turns out to work without dogging the test time"," lets comment on 6000 that it intends to trigger pagination '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,2,2017-04-16 02:31:46,4.25,,1,,"b""b' Ps might end up wanting to chop this into slices ex maybe 100 accept commands with 60 spans each (guessing at cardinality that is best). This implies mild join on async work"," but could considerably speed up test execution.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,3,2017-04-16 02:31:46,8.97,,1,,"b'b"" Was hoping that this would have triggered it.  Setting the fetch size to something lower immediately triggers it so I\'m a bit puzzled why this didn\'t.  I\'m going to close this for now until I can trigger this in a local test.  Then I will tackle the accept async join bit.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,closed,2017-04-16 03:09:30,37.73,0,4,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,4,2017-04-16 02:31:46,46.78,,,1,"b'b"" Locally I\'ve been able to trigger this error with as few as 2000 traces.  After some investigation I see that the Cassandra tests are skipped in the Travis PR builds which is why this PR didn\'t fail.  Also doubling the trace count didn\'t have a noticeable impact on test time so I\'m wondering if its worth the effort to fan out the accept calls.  I can still add that if it seems valuable though.  Right now I\'m not sure how to trigger the failure in a pull request without merging it which will surely break the build :)""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,reopened,2017-04-16 04:21:00,71.5,0,4,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,5,2017-04-16 02:31:46,25.03,,,1,"b""b' reopened as circleci was turned off for forks!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,6,2017-04-16 02:31:46,1.33,,1,,"b'b"" so my advice would be to use the least amount to trip the test (document the count).  Then"," you can cherry-pick this commit into the one that fixes it (essentially this broken test doesn\'t merge until there\'s a fix)  sg?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,7,2017-04-16 02:31:46,8.17,,,1,"b""b' uh-oh.. passed circleci!!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,8,2017-04-16 02:31:46,2.92,,1,,"b""b' circle is running c* 3.10 iirc.. wonder if is version-specific", theparameter? On Sun, Apr 16, 2017 at 11:56 AM," Lance Linder wrote:>'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,9,2017-04-16 02:31:46,1035.42,,1,,"b""b' Looks like CircleCI is skipping the C* tests as well.  My suspicion is that C* is failing to fully start.  When I get a chance I will SSH into the build machine and look at the logs. '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,10,2017-04-16 02:31:46,202.83,,1,,b'b\' Thx for the tip. Makes sense On 17 Apr 2017 05:49,"Lance Linder""  wrote:>> Tests run: 60, Failures: 0, Errors: 0, Skipped: 41\''
zipkin	1565	closed	11	adriancole	2017-04-16 02:31:46	64.88		+1		b""b' trying this after noticing the process crash locally url '",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,12,2017-04-16 02:31:46,237.38,,1,,"b""b' ok I think this failure is legit. we probably need to dockerizecassandra tests and quit trying to run them in circleci (becausecircle starts cassandra even if it is never used and it is reallyfragile) url  On Mon", Apr 17, 2017 at 10:16 AM," Adrian Cole  wrote:'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,closed,2017-06-29 19:23:15,902.25,0,10,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1565,closed,-,-,-,0,10,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,opened,2017-06-19 18:41:13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,title,2017-06-19 18:41:13,00:00,,1,,"b""b' Adding ability to listen to multiple kafka10 topics via comma separated list'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,body,2017-06-19 18:41:13,00:00,,1,,"b""b' Useful for cases like span info from different environments coming from different topics"," etc.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,1,2017-06-19 18:41:13,111.77,1,,,"b'b"" seems handy", but would need a test and updates on the config docs. Also," we should make sure that this is something others agree with as I don\'t know the support implications of always using ConsumerRebalanceListener.  Sorry we don\'t have a kafka mailer at the moment. pinging @dgrabows as he touched this recently""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,2,2017-06-19 18:41:13,31.58,,1,,"b'b"" This change make sense to me.  I don\'t think the ConsumerRebalanceListener is a concern. That was already there and not introduced with this change. It gets used for the worker to maintain a list of currently assigned partitions. That list is only used in the tests for multiple consumer threads", where the test needs to wait until each consumer has some assignment before proceeding.  The listener will be invoked each time partitions are reassigned in the consumer group, which will only happen once per restart if running a single instance of the collector. If running multiple collectors, invocations will occur whenever a collector is started, stopped," or looses connectivity to the kafka brokers. Those should be relatively infrequent events.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,3,2017-06-19 18:41:13,1357.22,,,1,"b""b' ok great. @danielkwinsor mind adding a test? (can be as simple as checking that split worked)  lemme know if you need help with this'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,4,2017-06-19 18:41:13,183.75,,,1,"b'b"" I was figuring a request for tests would come :)  I definitely will do it when I can fit it between my heavy work queue.  My only concern is that area didn\'t look easy to mock", so I don\'t know when I\'ll be able to get to it.  Manual testing did show this worked out with single or multiple topics, but I didn\'t test things like whitespace," etc.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,5,2017-06-19 18:41:13,963.63,,1,,"b""b' looks like you might be able to write a simple test that uses package access to check ()  basically read-back that to show a simple split works. wanna try?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,6,2017-06-19 18:41:13,1048.43,,1,,"b""b' k very least this needs an update to the docs  and in zipkinlike.. '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,closed,2017-06-28 17:46:43,1385.5,1,5,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,7,2017-06-19 18:41:13,597.93,,1,,"b""b' All good or did I scare you off? :)'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1622,closed,8,2017-06-19 18:41:13,51.9,,,1,b'b\' All good... in the process of adding docs and tests, but rebased fromupstream and it wiped out my commit, then auto closed.  Expect by EoD. On Jun 28, 2017 11:15,"Adrian Cole""  wrote:>\''
zipkin	1622	closed	reopened	 - 	2017-06-28 21:26:10	219.45	1	6	3
zipkin	1622	closed	9	danielkwinsor	2017-06-19 18:41:13	139.7	+1			b'b"" I spent too long on the unit test and gave up.  It\'s much too hard to mock something coming from a constructor without powermockito.  Here\'s the code plus docs.""'
zipkin	1622	closed	closed	 - 	2017-06-29 07:23:43	597.55	2	6	3
zipkin	1622	closed	10	adriancole	2017-06-19 18:41:13	597.22			+1	b'b"" Thanks very much @danielkwinsor! (and thanks for the timeboxed attempt on tests.. I\'ll copy you on a test commit)""'
zipkin	1622	closed	-	-	-	-	2	6	4
zipkin	1648	open	opened	jprateekvmware	2017-07-07 22:47:00
zipkin	1648	open	title	jprateekvmware	2017-07-07 22:47:00	00:00		+1		b""b' Skip dependency links for missing intermediates'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,body,2017-07-07 22:47:00,00:00,,1,,"b'b"" Considering the example where the we have a dependencies from M1M1>M3 dependency should only be defined ", when we have M1 directly calling M3. Currently for our case we have got the API-Gateway as entry point , which in turn invoke the central service, which in turn route the request to other services.  AG>CS>(M1,M2,M3)  Valid dependencies in the system are.  AG>CS>(M3) AG>CS>(M1) AG>CS>(M2)  Whereas below created dependency are invalid. AG>(M1) AG>(M2)  Reason why we could have above incorrect dependency could be many reason.  CS span gets dropped out: In that case M1,M2 would have CS span id as their parent span id in the JSON record, which would not exist in the zipkin database, While defining the dependencies we need to validate whether all such dependent span id exist," if they don\'t exist then ignore that span record for dependency calculation.""'",,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,1,2017-07-07 22:47:00,3.65,,1,,"b""b' No problem"," they can be generated and processed out of order.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,2,2017-07-07 22:47:00,20.38,,1,,"b""b' So in that case we need to have a fix in zipkin dependencies", as it showing dependencies from M1 >M3, when some of the M2 traces have got dropped , it should take into account the parent span id of M3 (which is m2 span id) and whether it exist in system , before defining the dependencies," else it gets a wrong picture projected '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,3,2017-07-07 22:47:00,175.6,,,1,b'b\' Sounds possible to remedy, but it also is easy to miss a detail. To make sure we are clear, can you post a simplified json with a missingspan and the links you expect and what heuristic you would use to decidehow to create the pseudo link? Even better a pull request. On 8 Jul 2017 07:11,"jprateekvmware""  wrote:>\''
zipkin	1648	open	4	jprateekvmware	2017-07-07 22:47:00	1277.53		+1		b""b' Done Will track as part of it url '",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,closed,2017-07-10 23:24:10,37.17,0,5,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,5,2017-07-07 22:47:00,170.48,,1,,"b'b"" please don\'t re-open the issue there.. the tests are here", and likely any code around it will be," too.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,reopened,2017-07-11 02:14:39,170.48,0,6,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,6,2017-07-07 22:47:00,80.18,,1,,"b'b\' @jprateekvmware I\\\'ve changed the title of this to ""Skip dependency links for missing intermediates"" as that\\\'s the best I can understand your scenario so far.  Can you explain why you are creating child spans in an intermediary", but not reporting them to Zipkin. It is one thing for this to be an exception, but it is certainly unexpected to do routinely. Help me understand?\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,7,2017-07-07 22:47:00,81.17,,1,,"b""b' ps you can also hop on gitter to chat about this"," too url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,8,2017-07-07 22:47:00,86.22,,1,,"b""b' Viewing JSON will reduce the round-trips on this issue (and spam to folks subscribed)"," please attach a pasted link to json of a trace that matches this scenario before proceeding further.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,9,2017-07-07 22:47:00,1105.53,,,1,"b""b' I will be there"," Thanks adrian'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,10,2017-07-07 22:47:00,1206.42,,,1,"b""b' Publishing the JSON payload. Dependencies is captured as api-gateway->M1-servicewhereas when i track the dependency tree based on parent id its perfect  api-gateway- '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,11,2017-07-07 22:47:00,1373.07,1,,,"b'b"" @jprateekvmware There are a large number of data errors in your trace. Make sure you are using latest versions of whatever instrumentation you are using", then try again. I\'ve parsed the easy to spot problems below:  span 94aa5c0443cc5582: there\'s an instrumentation bug as a span should have at most one core annotation (core annotation is cs, sr, ss, cr). Yours has 2 servers responding to a single client. span b963390959854a97 b49392870c173a9f: these are client spans, but have their endpoint (the one on cs, cr) marked as the same as its remote (the one on sa). This seems like a bug unless they are supposed to be calling themselves? They are also missing http tags, which are placed on their parents. more on that below: span fe70d9705ea17279 f5f9dcc8edb20ae7: these look a bit distracting as they have http tags (binary annotations), yet are marked local. These will be treated as process local spans," but they seem to be half-the-data of their children.""'",,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,12,2017-07-07 22:47:00,163.8,,1,,"b""b' I got all the traces arranged and it seems the Api-gateway is pointing to m1-service. 94aa5c0443cc5582>f5f9dcc8edb20ae7", seems problem with the way the data is generated from the Spring Sleuth," I will try having it updated with the latest version. it does not seems zipkin -dependency for the above JSON issue. ![image]url  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,13,2017-07-07 22:47:00,169.17,,1,,"b""b' OK please get back once things are upgraded as sleuth fixes a lot ofthings. By not troubleshooting until you have things up to date"," it alsoreduces the amount of times folks following this repo are spammed withcomments.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,14,2017-07-07 22:47:00,549.82,,1,,"b""b' @jprateekvmware is there still an issue with the latest versions?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1648,open,-,-,-,1,12,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,opened,2017-12-17 17:04:31,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,title,2017-12-17 17:04:31,00:00,,1,,"b""b' Fix SelectFromSpan with 128bit TraceIDs and strict-trace-id=false'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,body,2017-12-17 17:04:31,00:00,,1,,"b""b' In table", Trace IDs are stored in two fields: and  ," both of which are 16 characters long.  cc @adriancole '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,1,2017-12-17 17:04:31,941.7,,1,,"b""b' trying to make a test break around this url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,closed,2017-12-18 08:46:13,941.7,0,3,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,reopened,2017-12-18 08:46:17,0.07,0,3,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,2,2017-12-17 17:04:31,344.72,,,1,"b""b' OK rebased over the tests that underpin this. Thanks again!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,3,2017-12-17 17:04:31,5.67,,1,,"b""b' Guess you can just squash my prior commit into your second one", to make Git history a bit more cleaner," since that block of code changed a lot.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,4,2017-12-17 17:04:31,909.63,,1,,"b""b' ok fixed mysql from under this change"," so hopefully will build green'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,closed,2017-12-19 07:18:23,1352.1,0,5,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1851,closed,-,-,-,0,5,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,opened,2018-01-15 23:57:29,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,title,2018-01-15 23:57:29,00:00,,1,,"b""b' Adding the ability to import traces from JSON into zipkin-ui'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,body,2018-01-15 23:57:29,00:00,1,,,"b""b' I got tired of having no way to view previous traces in Zipkin.  Since it provides a way to download the trace JSON I figured there should be a way to add it back.  This adds a new link with the ability to select a JSON file for upload (as opposed to  due to the potential size of traces"," ref: url  and view it just like any other trace.  Relates to: #1747.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,1,2018-01-15 23:57:29,69.92,,,1,"b""b' interesting! for a impl summary"," is the trace in browser local storage or is it sortof a one-shot deal? Can you attach screen shots? Is there anything sharable between  and anything else?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,2,2018-01-15 23:57:29,958.03,1,,,"b'b"" 1. It\'s a one shot deal.  You refresh the page and you have to browse for the file again. 2. Attaching. 3.  _is_  with just a couple of small changes.  I did a horrible job committing it (it should\'ve been a copy).  If you have a good reference for how I can share more between the two", accounting for the small changes," I\'d be happy to refactor a bit.  ![traceimport-browse]url  ![traceimport-view]url Edit: updated images to reflect new link name.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,3,2018-01-15 23:57:29,406.58,,1,,"b'b\' kindof chummy but I almost like ""paste a trace"" better. Import mightconfuse people", or at least it did me.\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,4,2018-01-15 23:57:29,5.32,,,1,"b""b' You da boss!  Say the words and I will make the change :)'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,5,2018-01-15 23:57:29,9.78,,1,,"b'b"" some dangling concerns are that the UI doesn\'t natively speak v2 yet", so however worded, this implies the data is in v1 format.  The v2 format is in zipkin-js.. I wonder if there\'s a way we can leverage that to allow pasting of v2. If we have this feature," it should work with new data.  PS still need others feedback cc @ ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,closed,2018-01-17 17:23:09,1045.67,2,3,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,6,2018-01-15 23:57:29,1081.53,1,,,"b'b"" So", I just realized I messed up the commit a bit (new to and hating git, sorry).  So bear with me for a bit while I try to correct things.  Edit: Corrected but in 2 commits this time :\\\\  Also," I do agree this should work with v2 data.  But at the moment I\'m not sure where zipkin-js is or how to update it to work with v2 data.  I\'d be happy to help with what I can given the right direction but for now I\'ll wait for the feedback from others.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,reopened,2018-01-17 18:08:39,45.5,3,3,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,7,2018-01-15 23:57:29,335.02,,1,,b'b\' Haha if you have a trace with 9k spans you will have other problems. In any case better to profile the concern and check what the impact is. At some point the native format will be v2 which means this conversion willnot happen so it is temporary. On 20 Jan 2018 6:55 am,"Logic-32""  wrote:>\''
zipkin	1884	closed	8	eirslett	2018-01-15 23:57:29	1.73			+1	b'b"" Looping through 10k elements in JS is still quicker than touching the DOM, I don\'t think it will be a problem. (But don\'t take my word for it, might be a good idea to profile it.) I would be concerned if it took more than 30ms.""'
zipkin	1884	closed	9	adriancole	2018-01-15 23:57:29	4.78			+1	b'b\' Could  with a comment or add a dependency on zipkin-js and usethe functions directly. Usually we do rule of three on extracting code inupstream projects (ex hopefully arent many use cases for converting to v1so ideally we dont end up with 3 requests!) . Maybe see how it goes firstthen we can handle that as it arises (easier to see impact this way? Appreciate your effort and patience! On 20 Jan 2018 7:43 am, ""Adrian Cole""  wrote: Haha if you have a trace with 9k spans you will have other problems. In any case better to profile the concern and check what the impact is. At some point the native format will be v2 which means this conversion willnot happen so it is temporary. On 20 Jan 2018 6:55 am, ""Logic-32""  wrote:>\''
zipkin	1884	closed	10	Logic-32	2018-01-15 23:57:29	26.12			+1	b'b""  Lol.  Perhaps.  But it is an unfortunate fact of life in the system I work on.  It\'s not really all that common but I deal with the worst-of-the-worst so I have the unfortunate pleasure of seeing it daily :\'( Touche!  My head must be in the clouds right now :)the functions directly.  Will start with  and update the pull request when I can.  No promise on ETA given work priorities and such :\\\\""'
zipkin	1884	closed	11	Logic-32	2018-01-15 23:57:29	1322.15	+1			b'b\' Back to working on this. Just found out that with partials I can. Ref: url  url  <-I have to add the \\\'noShortcut\\\' option to do so.  Which isn\\\'t a hard refactor to do but before I go through that effort I wanted to run it by you to see how important it was before I did?  Also, I renamed ""Import A Trace"" to ""View Saved Trace"".  I added some missing i18n properties as well.  No translations, just the properties and default values.  Hopefully that doesn\\\'t mess with the foreign languages too much :\\\\  Reference pictures in prior post updated to reflect these changes.  (commit to follow...)\''
zipkin	1884	closed	12	drolando	2018-01-15 23:57:29	1198.93		+1		b'b"" Isn\'t the JSON returned by the UI valid V2 format? Couldn\'t you simply POST it back to / and use the UI as usual?""'
zipkin	1884	closed	13	adriancole	2018-01-15 23:57:29	6.63	+1			b'b"" @drolando right now the UI doesn\'t mount any write endpoints, and search etc is limited by original timestamp. to change to mount write endpoints might interfere with some folks assumptions about the security of their UI (right now, if you cut at /zipkin/* there\'s no way to poison or otherwise trace data). There is a different change that wasn\'t universally popular about writing to a separate storage service #1747.  On the technical bits, the v2 conversion etc code will end up replacing the v1 code in the project, so some of this is temporary technical debt.  hope this background is useful""'
zipkin	1884	closed	14	Logic-32	2018-01-15 23:57:29	291.95		+1		b""b' @drolando, in addition to what Adrian said, where I work we have a habit of attaching trace JSON to bug cases as output via the JSON button in the UI.  Without this feature, or some other tool to import the JSON, the trace JSON is pretty useless.  We have no desire to actually re-persist the JSON since our ES cluster is already pretty full of Zipkin data.  So this makes for a nice on-the-fly viewing of data with no storage overhead.  @adriancole, any updates on feedback from the core team?'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,15,2018-01-15 23:57:29,641.85,,,1,"b'b"" PS I am also in favor of this feature as I routinely need to check people\'straces and right now I have to post in order to do so. For support", this isa nice thing," as not always is the problem I\'m looking at storage specific(usually it is instrumentation specific)""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,16,2018-01-15 23:57:29,6.27,,1,,"b'b"" @Logic-32 can you look at the test dir and see if you can make a similar test for anything that\'s new here (possibly for the conversion part"," copy some test code from zipkin-js). This is a lot of new code and having at least some coverage will help if there\'s a bug we need to sort out later""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,17,2018-01-15 23:57:29,39.03,1,,,"b'b\' PS the UI still says ""view a saved trace"" which is confusing as data in zipkin is saved.  I wonder if the upload functionality should be a widget next to ""go to trace"" Ex instead of going to a trace by ID", we are going to an offline trace (by choosing the file). Regardless, I feel a bit off about the json viewer being mixed in with server side stuff like dependencies," as it is offline..  One way is to change ""go to trace"" to ""enter trace ID"" and put another widget directly under that says ""choose trace json""  I tried the functionality and notice I can\\\'t collapse any of the spans (even clicking expand-all collapse-all). Might want to check that.\''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,18,2018-01-15 23:57:29,358.68,,1,,"b'b\'  That\\\'s because I changed it from ""Import a Trace"" ;) Maybe?  It could certainly clear up the verbiage issue we\\\'re having.  I attached a rough mockup below of what it would look like (in IE).  Having it below the ""go to trace"" box isn\\\'t really practical as I don\\\'t think Bootstrap navs support multi-row very well (at least", I\\\'ve never seen one).  Either way, I can\\\'t say it looks very clean.  It\\\'s not immediately obvious which textbox should be used for what purpose without some descriptive text around the file input.  Additionally, there are some workflow complications with doing it that way.  After selecting the file we\\\'d have to change the URL to remove any reference to current state.  Otherwise somebody may try to  it and expect the same results.  Which won\\\'t happen.  We can use JS to fix the URL but we have to be careful with history management so the  buttons work as expected.  So the short version is that I believe a dedicated page for viewing the traces is the simplest way to do it.  But I\\\'m not sure how to disambiguate the online from offline stuff like you\\\'re concerned about.  We can consider a multi-level nav but that means extra clicks to get to a page.  With as simple as the UI is at the moment I don\\\'t think that\\\'s appropriate either.  ![mock-ie]url  Works on my box in Zipkin 2.4.6 with this change applied.  Tried IE, FF, and Chrome.  Behaves identically to  traces.  Did those work for you?  Which  were you using?  p.s. Will try to find a test to add when I can.\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,19,2018-01-15 23:57:29,200.73,1,,,b'b\' Just got tests added for the span conversion stuff.  Unfortunately there is a somewhat higher level bug that may make them moot.  Currently, the //{traceIdHex} has an optional query parameter to dump raw traces.  From what I can tell, getting that dump avoids some timestamp adjustments and sorting that a non-raw dump would do.  Unfortunately, it seems like //{traceIdHex} defaults to the same /v1 raw behavior.  Now, it\\\'s unfortunate because the UI doesn\\\'t like it when the  span isn\\\'t the first in the list of spans.  It actually fails quite miserably when that\\\'s the case.  Additionally, the lack of timestamp adjustments can cause spans to render in odd places on the timeline.  Is this something that would hold up this feature?  If so, I have no idea how I\\\'d handle the situation at the moment.  For reference: We just deployed Zipkin 2.4.2 to our production servers so I was using it as my test case I dumped a normal v1 trace, a raw one, and a v2 trace for comparison The normal v1 trace rendered properly," neither of the latter did The raw v1 trace and v2 trace rendered identically after moving the root span up to be the first span  p.s.  How does ""View Local Trace"" sound?\''",,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,20,2018-01-15 23:57:29,292.47,,1,,"b'b"" Thanks for the update and all the hard work @Logic-32.  yes", we decided that in v2 it would be best to move the adjustment logic to javascript in the UI (which makes a fake root span etc), just this hasn\'t been done. I forgot about this.  The key part is this logic (around sorting the trace by the root span) url There is also clock skew logic," which would might be something we can punt slightly. url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,21,2018-01-15 23:57:29,215.65,,,1,"b'b"" Happy to help @adriancole :)  However", I\'m not sure I\'m up for porting those changes over.  I know  well enough but it\'s a lot of ... and some other priorities have come up for me.  Is it a requirement to have those working before the change can be merged?  If so, what other options do we have?  At a minimum, I could probably implement a sort routine to at least make sure the root span is first in the list.  That\'s about all I\'d have time for.  And if I did that," would you want me to do it for raw v1 traces as well?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,22,2018-01-15 23:57:29,47.95,,,1,"b'b"" @Logic-32 thanks for being transparent about what you can budget attention for. It has been a great help so far. I think that the sort-based thing should happen after any potential conversion to v1 and before the existing logic is invoked. What I mean is that I\'d solve order for v1 raw (which should transitively solve for v2). Limit to sorting and then we\'ll open an issue to progress further. Sound good?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,23,2018-01-15 23:57:29,673.02,,,1,"b""b' Sounds good to me!  Will update when I can.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,24,2018-01-15 23:57:29,1214.7,,1,,"b""b' another release will be on the way soon. any chance this might be ready?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,25,2018-01-15 23:57:29,170.4,,,1,"b""b' Was able to look at sorting a little bit last week.  Going to try and  today :)  Edit: done.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,26,2018-01-15 23:57:29,675.3,,1,,"b""b' testing now'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,27,2018-01-15 23:57:29,16.3,,,1,"b""b' I will test this with normal span. then merge and add code for messaging span. Good stuff!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,28,2018-01-15 23:57:29,61.18,,1,,"b'b"" there\'s some interesting offset rendering I\'m looking into..""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,29,2018-01-15 23:57:29,5.52,,1,,"b""b' for example"," the UI is misaligned unless you stretch the screen carefully   '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,30,2018-01-15 23:57:29,272.73,,,1,"b""b' ![screen shot 2018-03-15 at 4 47 00 pm]url Looks like the left positioning is present on trace viewer but not the normal trace screen'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,31,2018-01-15 23:57:29,13.95,,1,,"b""b' getting somewhere now..'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,32,2018-01-15 23:57:29,7.15,,1,,"b'b"" ok it is because when we switch to v1 format we aren\'t merging by ID like the v1 api does.  ![screen shot 2018-03-15 at 5 08 06 pm]url  ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,33,2018-01-15 23:57:29,135.85,,,1,"b'b"" ok since this is on your master branch"," I\'m not going to push a commit to it. I\'ll make a commit to fix the merging thing and squash yours into it on the way in. will finish up tonight. Thanks for the help!""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,34,2018-01-15 23:57:29,264.75,,1,,"b'b"" To make sure I understand correctly: 1. You\'re trace is in v2 format and there is an issue converting to v1. 2. You\'re going to essentially merge this request while simultaneously fixing the bug? 3. Sorry for this being on my master branch.  Still new to git and didn\'t think about that.  I\'m honestly going to delete the repo once it gets merged though so feel free to do whatever :)   Deleting the repo so I can start  properly if I make more changes. 4.  You\'re welcome"," and thank you!""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,35,2018-01-15 23:57:29,869.07,,1,,"b""b' Thanks @Logic-32 I squashed yours and added 355a96f2cd6b09e788cc0ecab044cd89291b6fa7 for the merge thing (as without it the UI was weird). will make follow-up now for messaging spans'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,closed,2018-03-16 06:18:32,729.88,7,17,13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,36,2018-01-15 23:57:29,526.27,,,1,"b""b' Awesome!  Thank you for fixing up that merging issue for me :)'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1884,closed,-,-,-,7,17,14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,opened,2018-03-16 03:41:36,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,title,2018-03-16 03:41:36,00:00,,1,,"b'b"" Switch to use Cassandra-3.11.3\'s DelimiterAnalyzer and PREFIX mode SASI for the annotations index in the Zipkin2 Cassandra storage""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,body,2018-03-16 03:41:36,00:00,,,1,"b""b' This PR is waiting for Cassandra-3.11.3 to first be released.  It switches the SASI used for the annotation_query from the expensive (cpu", latency and disk space) to the fast efficient that was provided by @zuochangan and made available via [CASSANDRA-14247]url ref: url To test Zipkin with the new Delimiter Tokenizer, which will be available in Cassandra-3.11.3, do the following steps:  # clone and build Cassandra (3.11.2-SNAPSHOT)   git clone url  cd cassandra   git checkout cassandra-3.11   ant artifacts   # start Cassandra  -f  # clone Zipkin   git clone url  cd zipkin   git checkout -cassandra-delimiter-indexer-for-annotations  # Build the server and also make its dependencies   ./mvnw -DskipTests also-make -pl zipkin-server clean install   # start Zipkin   cd  java -jar ./zipkinserver-*  # open url  To stress-test the Zipkin schema that uses the new Delimiter Tokenizer  # start Cassandra (as above)   \\xe2\\x80\\xa6   # create stress friendly zipkin keyspace and schema   cd zipkin-/   cqlsh -f zipkin2-test   # warmup, and create initial writes   cassandra-stress  user profile=spanops\\\\(insert=1\\\\)  duration=1m  -rate threads=4 throttle=50/s   # stress   cassandra-stress  user profile=spanops\\\\(insert=10,by_trace=1,by_trace_ts_id=1,by_annotation=1\\\\)  duration=1m  -rate threads=4 throttle=50/s  -errors retries=10 ignore   # repeat, increasing throttle, threads, and duration. and graph to html if desired.   cassandra-stress  user profile=spanops\\\\(insert=10,by_trace=1,by_trace_ts_id=1,"by_annotation=1\\\\)  duration=1h  -rate threads=16 throttle=10000/s -errors retries=10 ignore -graph file=zipkin_1948.html title=Zipkin revision=with_delimiter_idx  '""",,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,1,2018-03-16 03:41:36,10.7,,,1,"b'b\' looks sweet. should ping @ about those running ""cassandra3"" if they can upgrade. I like this.  Will be nice to see the storage impact before and after", and some throughput difference.\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,2,2018-03-16 03:41:36,101.92,,1,,"b'b"" cql version check is done elsewhere.. I don\'t think impl version is...""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,3,2018-03-16 03:41:36,228.77,,1,,"b'b""  Here you go @adriancole \\xe2\\x80\\xa6 These are the numbers for three separate benchmarks", each running for an hour with, as much throughput as possible, Cassandra-3.11.2 without the annotations index Cassandra-3.11.3 with the new delimiter SASI annotations index Cassandra-3.11.2 with the previous CONTAINS SASI annotations index  It\'s visible from these that the new delimiter SASI annotations index is almost as fast as with no annotations index, both of which are ~20x as fast as the previous CONTAINS SASI annotations index. Both Cassandra and the stress client ran on the same Lenovo X1 Carbon gen5 (Intel Core i7-5600U Processor," 8Gb RAM) with Ubuntu 17.10. ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,4,2018-03-16 03:41:36,6.22,,1,,"b""b' And screenshots of the benchmarking graphs.  Operations per second. Mean latencies. 99th latencies. '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,5,2018-03-16 03:41:36,93.22,,1,,"b""b' The original benchmarking graph is available here: url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,6,2018-03-16 03:41:36,813.42,,1,,"b""b' @drolando fyi cassandra 3.11.3 is coming fast and once this merges should affect indexing a lot'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,7,2018-03-16 03:41:36,47.22,,1,,"b'b"" @adriancole @michaelsembwever I\'ll wait until C* 3.11.3 is out before upgrading to Cassandra 3 then.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,8,2018-03-16 03:41:36,0.82,,1,,"b'b"" @michaelsembwever Any idea about when they\'ll release the new version? I saw a blog post from 2 years ago about Cassandra doing monthly releases but that doesn\'t seem to be the case at all.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,9,2018-03-16 03:41:36,36.27,,1,,"b""b' rebased in preparation of the pending release of cassandra 3.11.3'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,10,2018-03-16 03:41:36,25.75,,1,,"b""b' I would expect we arent looking to change the api to substring match as apart of this change. I think we have negative tests for this actually. the like part was an impl detail of the old concat indexing but the specialbounded it around the query'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,11,2018-03-16 03:41:36,854.63,1,,,"b'b"" I didn\'t realize we had negative tests for this.  I was looking forward to the ability to do prefixed based searches :/  It makes sense not to change API contracts for this right now though.  P.S.  sorry for closing this.  Comment and Close is way to close to the Comment button :/""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,closed,2018-06-13 16:40:32,778.93,1,10,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,reopened,2018-06-13 16:40:39,0.12,1,10,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,12,2018-03-16 03:41:36,639.52,,1,,"b""b' fyi rebased this'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,13,2018-03-16 03:41:36,451.6,,1,,"b""b' rebased.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,14,2018-03-16 03:41:36,1085.78,,1,,"b""b' @adriancole Cassandra-3.11.3 is out. '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,closed,2018-08-03 07:08:40,868.02,1,13,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,15,2018-03-16 03:41:36,131.45,,,1,"b""b' Thanks much! we can release shortly'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,16,2018-03-16 03:41:36,136.13,,1,,"b""b' So instructions for folks is to basically recreate their keyspace right? (or use a different name)"," correct?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,17,2018-03-16 03:41:36,162.5,,,1,"b""b' hot dog!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,18,2018-03-16 03:41:36,164.85,,1,,"b""b'  The recommended approach would be to drop and create the keyspace.  Advanced users could just run as it drops the index and re-creates it (which will re-index existing data).  For example:  cqlsh -f zipkinschema-'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,19,2018-03-16 03:41:36,175.6,,,1,"b""b' great!'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,20,2018-03-16 03:41:36,495.17,,1,,"b""b' out in zipkin 2.11'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1948,closed,-,-,-,1,16,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1973,closed,opened,2018-03-28 05:12:55,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1973,closed,title,2018-03-28 05:12:55,00:00,,1,,"b""b' Skip filtering traces from result when STRICT_TRACE_ID is set to true'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1973,closed,body,2018-03-28 05:12:55,00:00,,1,,"b""b' url The check to remove traces from the result can be skipped if STRICT_TRACE_ID is enabled. '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1973,closed,1,2018-03-28 05:12:55,1128.05,,1,,"b""b' closed via #1974 '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1973,closed,closed,2018-09-25 20:35:55,923.0,0,3,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1973,closed,reopened,2018-11-20 02:46:02,370.12,0,3,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1973,closed,2,2018-03-28 05:12:55,168.78,,,1,"b'b"" We reverted this as we didn\'t have good test coverage. Basically the strict trace ID setting still includes the ability to read data prior to when the switch happened. That is test.  This makes the issue more difficult because on one hand", if data is uniform, we should totally never even try to do mixed stuff. OTOH, we do want people to use strict ID, so we have to facilitate migrations.  I think we can handle this a little differently by looking at the length of the trace IDs inside the search results.  One approach is: look to see if any trace IDs clash on lower 64bits. If there is no clash," don\'t filter. ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1973,closed,closed,2018-11-21 07:38:40,292.63,0,3,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,1973,closed,-,-,-,0,3,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2045,closed,opened,2018-05-09 14:01:09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2045,closed,title,2018-05-09 14:01:09,00:00,,1,,"b""b' To distinguish from the zipkin module.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2045,closed,body,2018-05-09 14:01:09,00:00,,1,,"b""b' This will cause a error in Eclipse when importing the project due to that there are two same artifacts in the maven project.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2045,closed,closed,2018-05-09 14:18:37,17.47,0,2,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2045,closed,reopened,2018-05-09 14:19:58,1.35,0,2,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2045,closed,closed,2018-05-09 14:20:16,0.3,0,2,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2045,closed,1,2018-05-09 14:01:09,562.37,,1,,b'b\'  As mentioned on #2046, the only reason you are experiencing a glitch is likely eclipse doesn\\\'t know what to name this on override. For example," Intellij names it ""zipkin (2)"" or something. There\\\'s likely a way to do this neater in eclipse", but also mentioned in that issue that this concern will go away when the old library () is removed.  In the future, I wouldn\\\'t recommend us dual-publishing libraries for more than a release cycle. Rather, we\\\'d keep a long running branch until there is no dependencies on  . However, we are were we are: there\\\'s work to do namely around the collector, UI and also mysql which implies we have at least a person-month of effort to get rid of dependencies on the v1 code.. maybe more than that.  Personally, I will be working on this effort when I return.\'',,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2045,closed,2,2018-05-09 14:01:09,625.35,,1,,"b""b' see url '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2045,closed,-,-,-,0,4,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,opened,2018-08-22 14:22:22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,title,2018-08-22 14:22:22,00:00,,1,,"b""b' Feature Request'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,body,2018-08-22 14:22:22,00:00,,1,,"b'b"" What kind of issue is this?  [ ] Feature Request.  hello\\xef\\xbc\\x8cin the Zipkin\'s V2  not support database \\xef\\xbc\\x9f""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,1,2018-08-22 14:22:22,578.07,,1,,"b""b' can you rephrase? we do have mysql but it is not considered productionlevel (also indeed it has a v1 style schema) what database are you looking for?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,2,2018-08-22 14:22:22,69.58,,1,,"b'b"" the zipkin\'s V1 is support mysql\\xef\\xbc\\x8cbut the zipkin\'s V2 not support\\xe3\\x80\\x82Do you plan to support mysql in zipkin\'s V2.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,3,2018-08-22 14:22:22,47.47,,,1,"b'b"" We don\'t have plans to change mysql at the moment. It is test onlyanyway", so effort isn\'t important. It is natively implemented with v2libraries," so you should be fine using it with any recent version ofzipkin and any data format we accept""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,4,2018-08-22 14:22:22,732.47,,,1,"b""b' thanks'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,closed,2018-08-23 14:10:01,1427.65,0,4,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,reopened,2018-08-24 08:23:11,1093.17,0,4,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,closed,2018-08-24 08:23:22,0.18,0,4,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2176,closed,-,-,-,0,4,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,opened,2019-01-17 12:44:31,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,title,2019-01-17 12:44:31,00:00,,1,,"b""b' Feature request:  storage option'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,body,2019-01-17 12:44:31,00:00,,1,,"b""b'  is an elastic-search based monitoring service We would like to contribute by adding  storage option along with Cassandra"," elastic-search and the rest.  Is that something you would be willing to merge in? '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,1,2019-01-17 12:44:31,1039.55,,,1,"b""b'  is very interesting and would welcome additional storage support. However it is best to keep it separate for now. We have several attempts to add influxDB", Postgresql," MongoDB but the interest faded. We can keep this in your repo and move when the community feels it is appropriate to merge it zipkin code.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,2,2019-01-17 12:44:31,117.7,,,1,"b""b' OK"," Thanks.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,closed,2019-01-24 08:01:46,1157.25,0,2,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,3,2019-01-17 12:44:31,14.73,,,1,"b'b"" @yyyogev To expand on Raja\'s answer", even if you build this outside of the Zipkin repo, it should be possible to run it with the standard Zipkin Server as an add-on module like some others we have (for example," see [zipkin-gcp\'s stackdriver storage component]url ""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,4,2019-01-17 12:44:31,4.52,,1,,"b'b"" I see.. If we do that"," does that mean we\'ll need to maintain it with every update of your repo?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,5,2019-01-17 12:44:31,22.78,,1,,"b""b' there will be some maintenance. but usually only version bumps and thiswould be the same maintenance in our org or elsewhere as extensions areseparate modules unless very reused and not saas only. while a new page we are starting to inventory community options such asscouter to help things become more popular. url  On Thu", Jan 24,2019," 4:21 PM Yogev Mets <notifications@ wrote:>'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,6,2019-01-17 12:44:31,28.4,,1,,"b""b' Ok then"," so how does it work? you would open a zipkin-logzio repo that we could work on?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,reopened,2019-01-24 09:15:51,74.08,0,5,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,7,2019-01-17 12:44:31,8.12,,1,,"b'b"" we wouldn\'t open a contrib repo without user demand", but you could start one and then see how it goes. For example, we have a minimum policy of rule-of-three where the 3 are end user sites that use something.. this helps with the fact that almost all here are volunteers and time must be used wisely.  If the api is the same, you might get by with a simple auto-config integration such as exists in elasticsearch for AWS. url you could make that repo named zipkin-logzio and if a future makes sense to use github\'s move repo functionality we can consider that at the time. Meanwhile," you can plug it in the options site as well.  make sense?""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,8,2019-01-17 12:44:31,2.87,,1,,"b'b"" ps there isn\'t a near future where this will be in the main repo which the issue is opened on. let\'s stop re-opening the issue and move conversation to url  as this issue is spamming all watchers""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,closed,2019-01-24 09:23:11,7.33,0,7,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,9,2019-01-17 12:44:31,4.95,1,,,"b""b' Ok"," sorry for that'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2355,closed,-,-,-,1,7,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,opened,2019-01-21 09:49:17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,title,2019-01-21 09:49:17,00:00,,1,,"b""b' Use es to store data", hit  /dependencies  api directly and set lookback to 0," then it returns data.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,body,2019-01-21 09:49:17,00:00,,1,,"b""b' ## while i use /dependencies api directly and set lookback to zero"," i hope it return empty list. but it still returns data.  Using es to store data. ![image]url  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,1,2019-01-21 09:49:17,1407.92,,1,,"b""b' There is no data on my visit.  url Data is available when searching  What is the reason for this?  Version 2.12.0 used '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,2,2019-01-21 09:49:17,1.02,,1,,"b""b' @yinjihuan you are using url  ?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,3,2019-01-21 09:49:17,18.05,,,1,"b""b' ![image]url  '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,4,2019-01-21 09:49:17,21.27,,,1,"b""b' ![image]url  Data is displayed in the Spring Cloud document example '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,5,2019-01-21 09:49:17,13.75,,1,,"b""b' can you join url  for troubleshooting instead of discussing on the issue?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,6,2019-01-21 09:49:17,1101.18,,1,,"b""b' @yinjihuan  you can set lookback to 0 and try again.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,closed,2019-02-12 04:32:28,1123.18,0,6,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,reopened,2019-02-12 04:32:33,0.08,0,6,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,7,2019-01-21 09:49:17,77.8,,1,,"b""b' I will make this fail same way as / when zeros are passed.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,closed,2019-02-18 06:45:16,132.72,0,7,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2356,closed,-,-,-,0,7,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,opened,2019-02-25 19:51:02,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,title,2019-02-25 19:51:02,00:00,,1,,"b""b' possible bug in zipkin-ruby or in the visualization'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,body,2019-02-25 19:51:02,00:00,,1,,"b""b' After updating to 2.12.2 we have seen that many of our traces get smashed to the left of the graph ![screen shot 2019-02-25 at 11 41 28 am]url When clicking on one of those I get:  ![screen shot 2019-02-25 at 11 42 36 am]url Only SA information. Looking at the json", these could be the relevant sections:   Note how the SA notation is alone in a different section of the JSON even when they have the same ID.  I assume the UI is rendering any one of the other depending on the orther it finds this information. Thus it gets an annotation with no further info and gets rendered this way.  These traces are being sent by the zipkin-ruby tracer. I suspect a bug there,  but please verify. Zipkin-ruby does *not* have support for v2 traces yet which can be the root of this.  If you determine this is a bug in the current UI," I do not care really as long as Lens do not have the same bug as we will migrate as soon as it is available in the stable image.   '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,1,2019-02-25 19:51:02,12.82,,1,,"b""b' CC @johnduhart'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,2,2019-02-25 19:51:02,244.65,,1,,"b'b\' what this smells like is v1 json encoding 1 instead of true for the ""sa""binary annotation.. could that be the case? in thrift boolean true isencoded as a byte with one bit set.. On Tue", Feb 26,2019, 3:51 AM Jordi Polo Carres wrote:>\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,3,2019-02-25 19:51:02,3.75,,1,,"b'b\' ""sa"" aside it looks like the span is sent in two documents instead of one.it is odd that the IP address would change during the same request on thesame host. usually that is symptomatic of a loopback RPC. Even if itweren\\\'t", we would have to guess which side of the RPC to stick the extraspan doc (the client or the server side). thanks for posting.. will think about it. meanwhile if there is a way tokeep stable endpoint info and post a single doc instead of two that will begood anyway.\'',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,4,2019-02-25 19:51:02,16.42,1,,,"b'b\' We are hardcoding to somehow we thought that was the way. We\\\'ll change that to (boolean or the string ""true""?) if you can verify. More weird still", I\\\'ve looked at the code and I see where we set the  , it is in the client span, which in fact it is in the trace also. At that point in the code there are other annotations, and they do show up:   and nowhere else the sa is setup, so really no idea where this particular sa with no extra info comes from.  So to summarize, we have 3 pieces here , a SERVER, a CLIENT, both I can find in the client code. And a SA which has no extra info which I can\\\'t find. Also we have the SA == 1 thing which if you tell me so I\\\'ll change to the boolean true. \'',,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,5,2019-02-25 19:51:02,21.45,,,1,"b'b\' change that to true (boolean or the string ""true""?) if you can verify. definitely boolean true (even if string might work)url  More weird still", I\\\'ve looked at the code and I see where we set the sa," itand that is a client attribute. ""sa"" should never be set on a server span.So", when the attribute is sent standalone, the parser assumes this is aclient span, as if a remote address in v1 format was set on a server span,"it would be ""ca"" (client address) not ""sa"" (server address) obv doing native v2 encoding would be  a win at some point (nudge nudge) asthat gets rid of the whole awkwardness and confusion around ""sa"" etc", asremoteAddress is harder to get wrong.\'',,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,6,2019-02-25 19:51:02,6.13,,1,,"b""b' The only place where I see SA  set is here   Which is a client span. I never see it in a server span. Yeah I want to do V2 also"," not enough hands'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,7,2019-02-25 19:51:02,8.33,1,,,b'b\' ok so in the initial example," it looks like maybe the data was missing some of the client part (only getting the ""sa"" info).. weird. anyway this is more a troubleshooting type of conversation. We should probably not do this in an issue as it spams everyone watching. Let\\\'s move to gitter? url \''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,closed,2019-02-26 01:04:35,313.55,2,6,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,8,2019-02-25 19:51:02,15.3,,1,,"b'b"" It is not missing information", the client span is there, the server span is there," and then there is this extra sa thing which I can\'t see where is coming from""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,reopened,2019-02-26 03:36:31,151.93,2,7,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,9,2019-02-25 19:51:02,148.0,,1,,"b'b\' Below is the complete json that creates this concern. I was able to reproduce it with the canonical  app hacked here url The only option I can think of in span conversion are hacks: * for address keyword in ""sa"" ""ca"" ""ma"" * leniently treat any binary annotation with address keyword as truthy (ex ignore the value which would let be same as  . The value is actually unimportant. * drop any binary annotation which has address keyword and a value besides true.  @ @drolando any opinons? \''",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,10,2019-02-25 19:51:02,5.93,,1,,"b""b' fwiw personally I am fine with conversions of address keywords ignoring the binary annotation value. As you can see in the image of the original trace"," mistaking remote address for local one really wrecks data conversion.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,11,2019-02-25 19:51:02,66.28,,1,,"b""b' url  should work around this"," but fixing the encoding should go out asap'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,closed,2019-02-27 03:39:36,3.08,2,10,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2414,closed,-,-,-,2,10,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,opened,2019-07-02 12:15:32,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,title,2019-07-02 12:15:32,00:00,,1,,"b""b' Consider what to do about OkHttp switching to Kotlin'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,body,2019-07-02 12:15:32,00:00,1,,,"b'b"" Currently", our elasticsearch module and server tests use OkHttp.. most important to end users is the elasticsearch module. I switched the version and it broke api a little   More importantly, this adds yet another 2MiB as that\'s the size of the kotlin standard library. Tests, we can use anything, but we should be considerate about the actual server code.  asking @ Java maintainers an opinion on this. I suspect it is either continue and not upgrade to OkHttp 4, upgrade to OkHttp 4 and accept the kotlin dep," or switch to Armeria and remember that we have some integrations downstream like zipkin-aws signatures which would need to be redone if we chose that path.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,1,2019-07-02 12:15:32,98.57,,,1,"b""b' Happy to help migrate things to Armeria'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,2,2019-07-02 12:15:32,779.6,1,,,"b'b"" @anuraaga if you are up to the port"," I\'d review it. Warning: there will be work in zipkin-aws even if not that bad and likely easier than what was done in zipkin-gcp""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,3,2019-07-02 12:15:32,703.67,,1,,"b""b' indeed I just hit that issue when trying to run with that consume conflicting versions of OkHttp.'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,4,2019-07-02 12:15:32,12.7,,1,,"b'b"" Started hacking on this today"," think it\'ll be fairly straightforward.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,5,2019-07-02 12:15:32,54.48,,1,,"b""b' after this can we expect a release after ?'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,6,2019-07-02 12:15:32,592.97,,1,,"b""b' '""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,7,2019-07-02 12:15:32,457.1,,1,,"b'b"" I\'m tired"," soon holidays :-)""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,8,2019-07-02 12:15:32,899.58,,1,,"b""b' ps the api break is our fault as it is an internal api. I can tentatively remove that to decouple things'""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,closed,2019-07-14 00:06:43,711.18,2,7,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,reopened,2019-07-15 11:01:35,654.87,2,7,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,9,2019-07-02 12:15:32,647.6,,1,,"b'b"" Realized it\'s premature to close this issue until zipkin-aws is migrated"," starting that now.""'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zipkin,2646,open,-,-,-,2,8,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
